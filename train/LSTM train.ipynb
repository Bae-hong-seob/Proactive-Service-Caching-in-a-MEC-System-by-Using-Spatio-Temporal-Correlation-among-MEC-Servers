{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1690642228271,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "C2y_S3-nJR4w",
    "outputId": "f5a19309-e562-4226-8b3b-fc8fbfe55488"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300, 9, 64)\n",
      "['train0.png', 'train1.png', 'train2.png', 'train3.png', 'train4.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import natsort\n",
    "from PIL import Image\n",
    "\n",
    "case = input()\n",
    "print('case :',case)\n",
    "\n",
    "file_path = './heatmap_case'+str(case)+'_0.2'\n",
    "file_list = os.listdir(file_path)\n",
    "file_list = natsort.natsorted(file_list, key=None, reverse=False, alg=0)\n",
    "\n",
    "num_of_files = len(file_list)\n",
    "\n",
    "# Assuming all images have the same height and width\n",
    "first_image = Image.open(os.path.join(file_path, file_list[0]))\n",
    "height, width = np.array(first_image).shape\n",
    "\n",
    "# Create an empty NumPy array to store the images\n",
    "image_array = np.empty((num_of_files, height, width))\n",
    "\n",
    "# Iterate through the file list and load images\n",
    "for i, file_name in enumerate(file_list):\n",
    "    image = Image.open(os.path.join(file_path, file_name))\n",
    "    image_array[i] = np.array(image)\n",
    "\n",
    "# image_array now contains the images as NumPy arrays\n",
    "print(image_array.shape)  # (num_of_files, height, width)\n",
    "print(file_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1690642228271,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "xEldMqsNUzZJ",
    "outputId": "d7b6866c-df6d-4a53-dbea-4969724a2324"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train0.png\n",
      "train1.png\n",
      "train2.png\n",
      "train3.png\n",
      "train4.png\n",
      "train5.png\n",
      "train6.png\n",
      "train7.png\n",
      "train8.png\n",
      "train9.png\n",
      "train10.png\n",
      "train11.png\n",
      "train12.png\n",
      "\n",
      "train1.png\n",
      "train2.png\n",
      "train3.png\n",
      "train4.png\n",
      "train5.png\n",
      "train6.png\n",
      "train7.png\n",
      "train8.png\n",
      "train9.png\n",
      "train10.png\n",
      "train11.png\n",
      "train12.png\n",
      "train13.png\n",
      "\n",
      "(1288, 13, 9, 64)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "num_of_frames = 13  # Specify the desired number of frames\n",
    "\n",
    "# Assuming all images have the same height and width\n",
    "first_image = Image.open(os.path.join(file_path, file_list[0]))\n",
    "height, width = np.array(first_image).shape[:2]\n",
    "\n",
    "# Create an empty NumPy array to store the images\n",
    "dataset = np.empty((num_of_files-num_of_frames+1, num_of_frames, height, width))\n",
    "\n",
    "# Iterate through the file list and load images\n",
    "for i in range(num_of_files-num_of_frames+1):\n",
    "    frame_images = file_list[i : i+num_of_frames]\n",
    "    for j, file_name in enumerate(frame_images):\n",
    "        if i < 2:\n",
    "            print(file_name)\n",
    "        image = Image.open(os.path.join(file_path, file_name))\n",
    "        dataset[i, j] = np.array(image)\n",
    "    if i < 2:\n",
    "        print()\n",
    "\n",
    "# dataset now contains the images bound into frames\n",
    "print(dataset.shape)  # (num_of_files // num_of_frames, num_of_frames, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1690642228271,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "8TrYB66sX_yI",
    "outputId": "2671a939-ca7d-496d-b750-d589adceb1d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1288, 13, 9, 64, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a channel dimension since the images are grayscale.\n",
    "dataset = np.expand_dims(dataset, axis=-1)\n",
    "dataset.shape #(num_of_samples, frames, height, width, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1690642228272,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "x8319gfKUkes",
    "outputId": "6c8e4095-c9f5-4cd6-bd53-9b1f0c44378c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1159, 13, 9, 64, 1) (129, 13, 9, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into train and validation sets using indexing to optimize memory.\n",
    "indexes = np.arange(dataset.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "train_index = indexes[: int(0.9 * dataset.shape[0])]\n",
    "val_index = indexes[int(0.9 * dataset.shape[0]) :]\n",
    "train_dataset = dataset[train_index]\n",
    "val_dataset = dataset[val_index]\n",
    "\n",
    "# Normalize the data to the 0-1 range.\n",
    "train_dataset = train_dataset / 255\n",
    "val_dataset = val_dataset / 255\n",
    "\n",
    "print(train_dataset.shape, val_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbydufV0bBt2"
   },
   "source": [
    "# RNN\n",
    "1. 각 MEC 당 128 input -> 128개 output.\n",
    "2. 과거 12개 관찰."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 8097,
     "status": "ok",
     "timestamp": 1690642236366,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "RHWKfIYubBt3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "window_size  = 12\n",
    "\n",
    "def create_shifted_frames(data, mec_index): # data = (frames, mecs, movieId, gray_scale)\n",
    "    tmp_data = data[:,mec_index,:,:]\n",
    "    tmp_data = np.squeeze(tmp_data)\n",
    "    tmp_data = tmp_data.transpose()\n",
    "\n",
    "    return tmp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1777,
     "status": "ok",
     "timestamp": 1690642238140,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "CCoGOWQ-bBt3",
    "outputId": "0c22e886-8587-4cab-d196-bc559497625e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 1, 100)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 1, 1)             101       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    inputs = layers.Input(shape=(window_size,1))\n",
    "    encoder = layers.LSTM(100, activation=\"relu\", return_sequences=False)(inputs)\n",
    "    repeat = layers.RepeatVector(1)(encoder)\n",
    "    decoder = layers.LSTM(100, activation='relu', return_sequences=True)(repeat)\n",
    "    outputs = layers.TimeDistributed(layers.Dense(1))(decoder)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    return model\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# observe_mec_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4876430,
     "status": "ok",
     "timestamp": 1690647114566,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "IymkXeEtVJrj",
    "outputId": "97fa4628-d8eb-46b8-d98c-0359eb03648f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1158  train ...\n",
      "no observe mec index\n",
      "8  번째 mec 학습 데이터 생성중 ...\n",
      "(64, 13)\n",
      "frame shape :  (64, 13)\n",
      "0  movie  train ...  (13,)\n",
      "1  movie  train ...  (13,)\n",
      "2  movie  train ...  (13,)\n",
      "3  movie  train ...  (13,)\n",
      "4  movie  train ...  (13,)\n",
      "5  movie  train ...  (13,)\n",
      "6  movie  train ...  (13,)\n",
      "7  movie  train ...  (13,)\n",
      "8  movie  train ...  (13,)\n",
      "9  movie  train ...  (13,)\n",
      "10  movie  train ...  (13,)\n",
      "11  movie  train ...  (13,)\n",
      "12  movie  train ...  (13,)\n",
      "13  movie  train ...  (13,)\n",
      "14  movie  train ...  (13,)\n",
      "15  movie  train ...  (13,)\n",
      "16  movie  train ...  (13,)\n",
      "17  movie  train ...  (13,)\n",
      "18  movie  train ...  (13,)\n",
      "19  movie  train ...  (13,)\n",
      "20  movie  train ...  (13,)\n",
      "21  movie  train ...  (13,)\n",
      "22  movie  train ...  (13,)\n",
      "23  movie  train ...  (13,)\n",
      "24  movie  train ...  (13,)\n",
      "25  movie  train ...  (13,)\n",
      "26  movie  train ...  (13,)\n",
      "27  movie  train ...  (13,)\n",
      "28  movie  train ...  (13,)\n",
      "29  movie  train ...  (13,)\n",
      "30  movie  train ...  (13,)\n",
      "31  movie  train ...  (13,)\n",
      "32  movie  train ...  (13,)\n",
      "33  movie  train ...  (13,)\n",
      "34  movie  train ...  (13,)\n",
      "35  movie  train ...  (13,)\n",
      "36  movie  train ...  (13,)\n",
      "37  movie  train ...  (13,)\n",
      "38  movie  train ...  (13,)\n",
      "39  movie  train ...  (13,)\n",
      "40  movie  train ...  (13,)\n",
      "41  movie  train ...  (13,)\n",
      "42  movie  train ...  (13,)\n",
      "43  movie  train ...  (13,)\n",
      "44  movie  train ...  (13,)\n",
      "45  movie  train ...  (13,)\n",
      "46  movie  train ...  (13,)\n",
      "47  movie  train ...  (13,)\n",
      "48  movie  train ...  (13,)\n",
      "49  movie  train ...  (13,)\n",
      "50  movie  train ...  (13,)\n",
      "51  movie  train ...  (13,)\n",
      "52  movie  train ...  (13,)\n",
      "53  movie  train ...  (13,)\n",
      "54  movie  train ...  (13,)\n",
      "55  movie  train ...  (13,)\n",
      "56  movie  train ...  (13,)\n",
      "57  movie  train ...  (13,)\n",
      "58  movie  train ...  (13,)\n",
      "59  movie  train ...  (13,)\n",
      "60  movie  train ...  (13,)\n",
      "61  movie  train ...  (13,)\n",
      "62  movie  train ...  (13,)\n",
      "63  movie  train ...  (13,)\n",
      "(9, 74176, 12, 1) (9, 74176)\n"
     ]
    }
   ],
   "source": [
    "X_train = [[] for _ in range(train_dataset.shape[2])]\n",
    "Y_train = [[] for _ in range(train_dataset.shape[2])]\n",
    "\n",
    "for day_index, oneday_dataset in enumerate(train_dataset):\n",
    "    for mec_index in range(oneday_dataset.shape[1]):\n",
    "        clear_output(wait=True)\n",
    "        print(day_index, ' train ...')\n",
    "        \n",
    "        try:\n",
    "            if mec_index != observe_mec_index:\n",
    "                continue\n",
    "        except:\n",
    "            print('no observe mec index')\n",
    "\n",
    "        print(mec_index,' 번째 mec 학습 데이터 생성중 ...')\n",
    "        frame_dataset = create_shifted_frames(oneday_dataset, mec_index)\n",
    "        print('frame shape : ', frame_dataset.shape)\n",
    "\n",
    "        X,Y = np.empty((1,12,1)), np.empty((1))\n",
    "        for movieId_index, movieId in enumerate(frame_dataset):\n",
    "            print(movieId_index, ' movie  train ... ', movieId.shape)\n",
    "            x = movieId[:-1]\n",
    "            x = np.array([[x[i] for i in range(j,j+window_size)] for j in range(len(x)-window_size+1)])\n",
    "            y = movieId[window_size:]\n",
    "            x = np.expand_dims(x, axis=-1)\n",
    "            #print('final X,Y shape : ',  x.shape, y.shape)\n",
    "            X = np.append(X,x, axis=0)\n",
    "            Y = np.append(Y,y, axis=0)\n",
    "\n",
    "        X = np.delete(X, 0, axis=0)\n",
    "        Y = np.delete(Y, 0, axis=0)\n",
    "        try:\n",
    "            X_train[mec_index].extend(X)\n",
    "            Y_train[mec_index].extend(Y)\n",
    "        except:\n",
    "            X_train[mec_index] = np.append(X_train[mec_index], X, axis=0)\n",
    "            Y_train[mec_index] = np.append(Y_train[mec_index], Y, axis=0)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_1 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(74176, 12, 1) (74176,)\n",
      "Epoch 1/20\n",
      "464/464 [==============================] - 69s 140ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "Epoch 2/20\n",
      "464/464 [==============================] - 66s 140ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "Epoch 3/20\n",
      "464/464 [==============================] - 68s 146ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "Epoch 4/20\n",
      "464/464 [==============================] - 64s 139ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "Epoch 5/20\n",
      "464/464 [==============================] - 64s 138ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "Epoch 6/20\n",
      " 55/464 [==>...........................] - ETA: 49s - loss: 0.0252"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    for mec_index in range(train_dataset.shape[2]): # mecs만큼 반복\n",
    "        print(mec_index,'mec 학습중 ...')\n",
    "        rnn_model = get_model()\n",
    "        print(rnn_model.summary())\n",
    "        print(X_train[mec_index].shape, Y_train[mec_index].shape)\n",
    "        rnn_model.fit(X_train[mec_index], Y_train[mec_index], epochs=20, validation_split=0.2, verbose=1, batch_size = 128)\n",
    "        rnn_model.save('./rnn_models/MEC'+str(mec_index)+'rnn_'+file_path[-9:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOpUcXClG8ECcBkwzfPGTbR",
   "mount_file_id": "1ZHgDD_jTvpgXzoRBbhcNUoQwM3bh22wU",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rnn-gpu",
   "language": "python",
   "name": "rnn-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
