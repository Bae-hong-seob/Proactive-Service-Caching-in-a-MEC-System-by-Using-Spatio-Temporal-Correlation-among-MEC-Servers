{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1690642228271,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "C2y_S3-nJR4w",
    "outputId": "f5a19309-e562-4226-8b3b-fc8fbfe55488"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300, 9, 64)\n",
      "['train0.png', 'train1.png', 'train2.png', 'train3.png', 'train4.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import natsort\n",
    "from PIL import Image\n",
    "\n",
    "file_path = './heatmap_case2_0.2'\n",
    "file_list = os.listdir(file_path)\n",
    "file_list = natsort.natsorted(file_list, key=None, reverse=False, alg=0)\n",
    "\n",
    "num_of_files = len(file_list)\n",
    "\n",
    "# Assuming all images have the same height and width\n",
    "first_image = Image.open(os.path.join(file_path, file_list[0]))\n",
    "height, width = np.array(first_image).shape\n",
    "\n",
    "# Create an empty NumPy array to store the images\n",
    "image_array = np.empty((num_of_files, height, width))\n",
    "\n",
    "# Iterate through the file list and load images\n",
    "for i, file_name in enumerate(file_list):\n",
    "    image = Image.open(os.path.join(file_path, file_name))\n",
    "    image_array[i] = np.array(image)\n",
    "\n",
    "# image_array now contains the images as NumPy arrays\n",
    "print(image_array.shape)  # (num_of_files, height, width)\n",
    "print(file_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1690642228271,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "xEldMqsNUzZJ",
    "outputId": "d7b6866c-df6d-4a53-dbea-4969724a2324"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train0.png\n",
      "train1.png\n",
      "train2.png\n",
      "train3.png\n",
      "train4.png\n",
      "train5.png\n",
      "train6.png\n",
      "train7.png\n",
      "train8.png\n",
      "train9.png\n",
      "train10.png\n",
      "train11.png\n",
      "train12.png\n",
      "\n",
      "train1.png\n",
      "train2.png\n",
      "train3.png\n",
      "train4.png\n",
      "train5.png\n",
      "train6.png\n",
      "train7.png\n",
      "train8.png\n",
      "train9.png\n",
      "train10.png\n",
      "train11.png\n",
      "train12.png\n",
      "train13.png\n",
      "\n",
      "(1288, 13, 9, 64)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "num_of_frames = 13  # Specify the desired number of frames\n",
    "\n",
    "# Assuming all images have the same height and width\n",
    "first_image = Image.open(os.path.join(file_path, file_list[0]))\n",
    "height, width = np.array(first_image).shape[:2]\n",
    "\n",
    "# Create an empty NumPy array to store the images\n",
    "dataset = np.empty((num_of_files-num_of_frames+1, num_of_frames, height, width))\n",
    "\n",
    "# Iterate through the file list and load images\n",
    "for i in range(num_of_files-num_of_frames+1):\n",
    "    frame_images = file_list[i : i+num_of_frames]\n",
    "    for j, file_name in enumerate(frame_images):\n",
    "        if i < 2:\n",
    "            print(file_name)\n",
    "        image = Image.open(os.path.join(file_path, file_name))\n",
    "        dataset[i, j] = np.array(image)\n",
    "    if i < 2:\n",
    "        print()\n",
    "\n",
    "# dataset now contains the images bound into frames\n",
    "print(dataset.shape)  # (num_of_files // num_of_frames, num_of_frames, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1690642228271,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "8TrYB66sX_yI",
    "outputId": "2671a939-ca7d-496d-b750-d589adceb1d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1288, 13, 9, 64, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a channel dimension since the images are grayscale.\n",
    "dataset = np.expand_dims(dataset, axis=-1)\n",
    "dataset.shape #(num_of_samples, frames, height, width, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1690642228272,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "x8319gfKUkes",
    "outputId": "6c8e4095-c9f5-4cd6-bd53-9b1f0c44378c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1159, 13, 9, 64, 1) (129, 13, 9, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into train and validation sets using indexing to optimize memory.\n",
    "indexes = np.arange(dataset.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "train_index = indexes[: int(0.9 * dataset.shape[0])]\n",
    "val_index = indexes[int(0.9 * dataset.shape[0]) :]\n",
    "train_dataset = dataset[train_index]\n",
    "val_dataset = dataset[val_index]\n",
    "\n",
    "# Normalize the data to the 0-1 range.\n",
    "train_dataset = train_dataset / 255\n",
    "val_dataset = val_dataset / 255\n",
    "\n",
    "print(train_dataset.shape, val_dataset.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "bbydufV0bBt2"
   },
   "source": [
    "# RNN\n",
    "1. 각 MEC 당 128 input -> 128개 output.\n",
    "2. 과거 12개 관찰."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 8097,
     "status": "ok",
     "timestamp": 1690642236366,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "RHWKfIYubBt3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "window_size  = 12\n",
    "\n",
    "def create_shifted_frames(data, mec_index): # data = (frames, mecs, movieId, gray_scale)\n",
    "    tmp_data = data[:,mec_index,:,:]\n",
    "    tmp_data = np.squeeze(tmp_data)\n",
    "    tmp_data = tmp_data.transpose()\n",
    "\n",
    "    return tmp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1777,
     "status": "ok",
     "timestamp": 1690642238140,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "CCoGOWQ-bBt3",
    "outputId": "0c22e886-8587-4cab-d196-bc559497625e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 1, 100)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 1, 1)             101       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    inputs = layers.Input(shape=(window_size,1))\n",
    "    encoder = layers.LSTM(100, activation=\"relu\", return_sequences=False)(inputs)\n",
    "    repeat = layers.RepeatVector(1)(encoder)\n",
    "    decoder = layers.LSTM(100, activation='relu', return_sequences=True)(repeat)\n",
    "    outputs = layers.TimeDistributed(layers.Dense(1))(decoder)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    return model\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# observe_mec_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1158  train ...\n",
      "no observe mec index\n",
      "8  번째 mec 학습중 ...\n",
      "frame shape :  (64, 13)\n",
      "0  movie  train ...  (13,)\n",
      "1  movie  train ...  (13,)\n",
      "2  movie  train ...  (13,)\n",
      "3  movie  train ...  (13,)\n",
      "4  movie  train ...  (13,)\n",
      "5  movie  train ...  (13,)\n",
      "6  movie  train ...  (13,)\n",
      "7  movie  train ...  (13,)\n",
      "8  movie  train ...  (13,)\n",
      "9  movie  train ...  (13,)\n",
      "10  movie  train ...  (13,)\n",
      "11  movie  train ...  (13,)\n",
      "12  movie  train ...  (13,)\n",
      "13  movie  train ...  (13,)\n",
      "14  movie  train ...  (13,)\n",
      "15  movie  train ...  (13,)\n",
      "16  movie  train ...  (13,)\n",
      "17  movie  train ...  (13,)\n",
      "18  movie  train ...  (13,)\n",
      "19  movie  train ...  (13,)\n",
      "20  movie  train ...  (13,)\n",
      "21  movie  train ...  (13,)\n",
      "22  movie  train ...  (13,)\n",
      "23  movie  train ...  (13,)\n",
      "24  movie  train ...  (13,)\n",
      "25  movie  train ...  (13,)\n",
      "26  movie  train ...  (13,)\n",
      "27  movie  train ...  (13,)\n",
      "28  movie  train ...  (13,)\n",
      "29  movie  train ...  (13,)\n",
      "30  movie  train ...  (13,)\n",
      "31  movie  train ...  (13,)\n",
      "32  movie  train ...  (13,)\n",
      "33  movie  train ...  (13,)\n",
      "34  movie  train ...  (13,)\n",
      "35  movie  train ...  (13,)\n",
      "36  movie  train ...  (13,)\n",
      "37  movie  train ...  (13,)\n",
      "38  movie  train ...  (13,)\n",
      "39  movie  train ...  (13,)\n",
      "40  movie  train ...  (13,)\n",
      "41  movie  train ...  (13,)\n",
      "42  movie  train ...  (13,)\n",
      "43  movie  train ...  (13,)\n",
      "44  movie  train ...  (13,)\n",
      "45  movie  train ...  (13,)\n",
      "46  movie  train ...  (13,)\n",
      "47  movie  train ...  (13,)\n",
      "48  movie  train ...  (13,)\n",
      "49  movie  train ...  (13,)\n",
      "50  movie  train ...  (13,)\n",
      "51  movie  train ...  (13,)\n",
      "52  movie  train ...  (13,)\n",
      "53  movie  train ...  (13,)\n",
      "54  movie  train ...  (13,)\n",
      "55  movie  train ...  (13,)\n",
      "56  movie  train ...  (13,)\n",
      "57  movie  train ...  (13,)\n",
      "58  movie  train ...  (13,)\n",
      "59  movie  train ...  (13,)\n",
      "60  movie  train ...  (13,)\n",
      "61  movie  train ...  (13,)\n",
      "62  movie  train ...  (13,)\n",
      "63  movie  train ...  (13,)\n",
      "(9, 74176, 12, 1) (9, 74176)\n"
     ]
    }
   ],
   "source": [
    "X_train = [[] for _ in range(train_dataset.shape[2])]\n",
    "Y_train = [[] for _ in range(train_dataset.shape[2])]\n",
    "for day_index, oneday_dataset in enumerate(train_dataset):\n",
    "    for mec_index in range(oneday_dataset.shape[1]):\n",
    "        clear_output(wait=True)\n",
    "        print(day_index, ' train ...')\n",
    "        \n",
    "        try:\n",
    "            if mec_index != observe_mec_index:\n",
    "                continue\n",
    "        except:\n",
    "            print('no observe mec index')\n",
    "\n",
    "        print(mec_index,' 번째 mec 학습중 ...')\n",
    "        frame_dataset = create_shifted_frames(oneday_dataset, mec_index)\n",
    "        print('frame shape : ', frame_dataset.shape)\n",
    "\n",
    "        X,Y = np.empty((1,12,1)), np.empty((1))\n",
    "        for movieId_index, movieId in enumerate(frame_dataset):\n",
    "            print(movieId_index, ' movie  train ... ', movieId.shape)\n",
    "            x = movieId[:-1]\n",
    "            x = np.array([[x[i] for i in range(j,j+window_size)] for j in range(len(x)-window_size+1)])\n",
    "            y = movieId[window_size:]\n",
    "            x = np.expand_dims(x, axis=-1)\n",
    "            #print('final X,Y shape : ',  x.shape, y.shape)\n",
    "            X = np.append(X,x, axis=0)\n",
    "            Y = np.append(Y,y, axis=0)\n",
    "\n",
    "        X = np.delete(X, 0, axis=0)\n",
    "        Y = np.delete(Y, 0, axis=0)\n",
    "        try:\n",
    "            X_train[mec_index].extend(X)\n",
    "            Y_train[mec_index].extend(Y)\n",
    "        except:\n",
    "            X_train[mec_index] = np.append(X_train[mec_index], X, axis=0)\n",
    "            Y_train[mec_index] = np.append(Y_train[mec_index], Y, axis=0)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_1 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(74176, 12, 1) (74176,)\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwangwoon\\anaconda3\\envs\\rnn-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464/464 [==============================] - 50s 105ms/step - loss: 0.0245 - val_loss: 0.0251\n",
      "Epoch 2/20\n",
      "464/464 [==============================] - 49s 106ms/step - loss: 0.0245 - val_loss: 0.0251\n",
      "Epoch 3/20\n",
      "464/464 [==============================] - 50s 107ms/step - loss: 0.0245 - val_loss: 0.0251\n",
      "Epoch 4/20\n",
      "464/464 [==============================] - 50s 108ms/step - loss: 0.0245 - val_loss: 0.0251\n",
      "Epoch 5/20\n",
      "464/464 [==============================] - 51s 109ms/step - loss: 0.0245 - val_loss: 0.0251\n",
      "Epoch 6/20\n",
      "464/464 [==============================] - 50s 108ms/step - loss: 0.0245 - val_loss: 0.0251\n",
      "Epoch 7/20\n",
      "464/464 [==============================] - 51s 109ms/step - loss: 0.0245 - val_loss: 0.0251\n",
      "Epoch 8/20\n",
      "464/464 [==============================] - 50s 107ms/step - loss: 0.0245 - val_loss: 0.0251\n",
      "Epoch 9/20\n",
      "464/464 [==============================] - 50s 108ms/step - loss: 0.0245 - val_loss: 0.0251\n",
      "Epoch 10/20\n",
      "464/464 [==============================] - 49s 106ms/step - loss: 0.0245 - val_loss: 0.0252\n",
      "Epoch 11/20\n",
      "464/464 [==============================] - 48s 104ms/step - loss: 0.0245 - val_loss: 0.0251\n",
      "Epoch 12/20\n",
      "464/464 [==============================] - 50s 108ms/step - loss: 0.0245 - val_loss: 0.0251\n",
      "Epoch 13/20\n",
      "464/464 [==============================] - 49s 106ms/step - loss: 0.0245 - val_loss: 0.0251\n",
      "Epoch 14/20\n",
      "464/464 [==============================] - 49s 105ms/step - loss: 0.0245 - val_loss: 0.0251\n",
      "Epoch 15/20\n",
      "464/464 [==============================] - 50s 108ms/step - loss: 0.0245 - val_loss: 0.0251\n",
      "Epoch 16/20\n",
      "464/464 [==============================] - 50s 108ms/step - loss: 0.0245 - val_loss: 0.0251\n",
      "Epoch 17/20\n",
      "464/464 [==============================] - 49s 107ms/step - loss: 0.0245 - val_loss: 0.0251\n",
      "Epoch 18/20\n",
      "464/464 [==============================] - 50s 107ms/step - loss: 0.0245 - val_loss: 0.0251\n",
      "Epoch 19/20\n",
      "464/464 [==============================] - 50s 109ms/step - loss: 0.0245 - val_loss: 0.0251\n",
      "Epoch 20/20\n",
      "464/464 [==============================] - 50s 107ms/step - loss: 0.0245 - val_loss: 0.0251\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC0rnn_case2_0.2\\assets\n",
      "1 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_2 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(74176, 12, 1) (74176,)\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwangwoon\\anaconda3\\envs\\rnn-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464/464 [==============================] - 51s 109ms/step - loss: 0.0237 - val_loss: 0.0234\n",
      "Epoch 2/20\n",
      "464/464 [==============================] - 51s 110ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 3/20\n",
      "464/464 [==============================] - 49s 106ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 4/20\n",
      "464/464 [==============================] - 49s 105ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 5/20\n",
      "464/464 [==============================] - 49s 105ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 6/20\n",
      "464/464 [==============================] - 50s 107ms/step - loss: 0.0237 - val_loss: 0.0234\n",
      "Epoch 7/20\n",
      "464/464 [==============================] - 49s 106ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 8/20\n",
      "464/464 [==============================] - 50s 107ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 9/20\n",
      "464/464 [==============================] - 50s 107ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 10/20\n",
      "464/464 [==============================] - 48s 104ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 11/20\n",
      "464/464 [==============================] - 50s 107ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 12/20\n",
      "464/464 [==============================] - 49s 105ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 13/20\n",
      "464/464 [==============================] - 49s 106ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 14/20\n",
      "464/464 [==============================] - 49s 106ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 15/20\n",
      "464/464 [==============================] - 48s 104ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 16/20\n",
      "464/464 [==============================] - 49s 106ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 17/20\n",
      "464/464 [==============================] - 49s 105ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 18/20\n",
      "464/464 [==============================] - 49s 105ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 19/20\n",
      "464/464 [==============================] - 48s 105ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 20/20\n",
      "464/464 [==============================] - 50s 108ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC1rnn_case2_0.2\\assets\n",
      "2 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_3 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(74176, 12, 1) (74176,)\n",
      "Epoch 1/20\n",
      "  1/464 [..............................] - ETA: 52s - loss: 0.0557"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwangwoon\\anaconda3\\envs\\rnn-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464/464 [==============================] - 49s 106ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 2/20\n",
      "464/464 [==============================] - 49s 106ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 3/20\n",
      "464/464 [==============================] - 49s 106ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 4/20\n",
      "464/464 [==============================] - 49s 106ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 5/20\n",
      "464/464 [==============================] - 50s 109ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 6/20\n",
      "464/464 [==============================] - 49s 106ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 7/20\n",
      "464/464 [==============================] - 50s 108ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 8/20\n",
      "464/464 [==============================] - 49s 105ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 9/20\n",
      "464/464 [==============================] - 50s 107ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 10/20\n",
      "464/464 [==============================] - 50s 108ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 11/20\n",
      "464/464 [==============================] - 48s 105ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 12/20\n",
      "464/464 [==============================] - 49s 107ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 13/20\n",
      "464/464 [==============================] - 49s 106ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 14/20\n",
      "464/464 [==============================] - 50s 107ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 15/20\n",
      "464/464 [==============================] - 49s 105ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 16/20\n",
      "464/464 [==============================] - 49s 106ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 17/20\n",
      "464/464 [==============================] - 49s 106ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 18/20\n",
      "464/464 [==============================] - 50s 107ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 19/20\n",
      "464/464 [==============================] - 50s 107ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 20/20\n",
      "464/464 [==============================] - 50s 108ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC2rnn_case2_0.2\\assets\n",
      "3 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_4 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(74176, 12, 1) (74176,)\n",
      "Epoch 1/20\n",
      "  1/464 [..............................] - ETA: 51s - loss: 0.0292"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwangwoon\\anaconda3\\envs\\rnn-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464/464 [==============================] - 48s 103ms/step - loss: 0.0241 - val_loss: 0.0247\n",
      "Epoch 2/20\n",
      "464/464 [==============================] - 48s 103ms/step - loss: 0.0240 - val_loss: 0.0247\n",
      "Epoch 3/20\n",
      "464/464 [==============================] - 47s 102ms/step - loss: 0.0240 - val_loss: 0.0247\n",
      "Epoch 4/20\n",
      "464/464 [==============================] - 47s 102ms/step - loss: 0.0240 - val_loss: 0.0247\n",
      "Epoch 5/20\n",
      "464/464 [==============================] - 47s 102ms/step - loss: 0.0240 - val_loss: 0.0247\n",
      "Epoch 6/20\n",
      "464/464 [==============================] - 48s 103ms/step - loss: 0.0240 - val_loss: 0.0247\n",
      "Epoch 7/20\n",
      "464/464 [==============================] - 47s 102ms/step - loss: 0.0240 - val_loss: 0.0247\n",
      "Epoch 8/20\n",
      "464/464 [==============================] - 47s 102ms/step - loss: 0.0240 - val_loss: 0.0247\n",
      "Epoch 9/20\n",
      "464/464 [==============================] - 47s 102ms/step - loss: 0.0240 - val_loss: 0.0247\n",
      "Epoch 10/20\n",
      "464/464 [==============================] - 50s 108ms/step - loss: 0.0240 - val_loss: 0.0247\n",
      "Epoch 11/20\n",
      "464/464 [==============================] - 47s 102ms/step - loss: 0.0240 - val_loss: 0.0247\n",
      "Epoch 12/20\n",
      "464/464 [==============================] - 45s 98ms/step - loss: 0.0240 - val_loss: 0.0247\n",
      "Epoch 13/20\n",
      "464/464 [==============================] - 45s 98ms/step - loss: 0.0240 - val_loss: 0.0247\n",
      "Epoch 14/20\n",
      "464/464 [==============================] - 48s 104ms/step - loss: 0.0240 - val_loss: 0.0247\n",
      "Epoch 15/20\n",
      "464/464 [==============================] - 48s 104ms/step - loss: 0.0240 - val_loss: 0.0247\n",
      "Epoch 16/20\n",
      "464/464 [==============================] - 48s 104ms/step - loss: 0.0240 - val_loss: 0.0247\n",
      "Epoch 17/20\n",
      "464/464 [==============================] - 49s 106ms/step - loss: 0.0240 - val_loss: 0.0248\n",
      "Epoch 18/20\n",
      "464/464 [==============================] - 51s 110ms/step - loss: 0.0240 - val_loss: 0.0247\n",
      "Epoch 19/20\n",
      "464/464 [==============================] - 49s 106ms/step - loss: 0.0240 - val_loss: 0.0247\n",
      "Epoch 20/20\n",
      "464/464 [==============================] - 49s 106ms/step - loss: 0.0240 - val_loss: 0.0247\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC3rnn_case2_0.2\\assets\n",
      "4 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_5 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(74176, 12, 1) (74176,)\n",
      "Epoch 1/20\n",
      "  1/464 [..............................] - ETA: 50s - loss: 0.0220"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwangwoon\\anaconda3\\envs\\rnn-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464/464 [==============================] - 49s 105ms/step - loss: 0.0229 - val_loss: 0.0228\n",
      "Epoch 2/20\n",
      "464/464 [==============================] - 49s 106ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 3/20\n",
      "464/464 [==============================] - 49s 105ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 4/20\n",
      "464/464 [==============================] - 50s 108ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 5/20\n",
      "464/464 [==============================] - 47s 102ms/step - loss: 0.0228 - val_loss: 0.0229\n",
      "Epoch 6/20\n",
      "464/464 [==============================] - 50s 108ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 7/20\n",
      "464/464 [==============================] - 47s 102ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 8/20\n",
      "464/464 [==============================] - 50s 108ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 9/20\n",
      "464/464 [==============================] - 48s 102ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 10/20\n",
      "464/464 [==============================] - 51s 111ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 11/20\n",
      "464/464 [==============================] - 47s 102ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 12/20\n",
      "464/464 [==============================] - 49s 105ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 13/20\n",
      "464/464 [==============================] - 50s 108ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 14/20\n",
      "464/464 [==============================] - 48s 104ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 15/20\n",
      "464/464 [==============================] - 50s 108ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 16/20\n",
      "464/464 [==============================] - 48s 104ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 17/20\n",
      "464/464 [==============================] - 49s 106ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 18/20\n",
      "464/464 [==============================] - 46s 100ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 19/20\n",
      "464/464 [==============================] - 49s 105ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 20/20\n",
      "464/464 [==============================] - 47s 100ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC4rnn_case2_0.2\\assets\n",
      "5 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_6 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(74176, 12, 1) (74176,)\n",
      "Epoch 1/20\n",
      "  1/464 [..............................] - ETA: 50s - loss: 0.0445"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwangwoon\\anaconda3\\envs\\rnn-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464/464 [==============================] - 49s 105ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 2/20\n",
      "464/464 [==============================] - 47s 101ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 3/20\n",
      "464/464 [==============================] - 48s 103ms/step - loss: 0.0241 - val_loss: 0.0240\n",
      "Epoch 4/20\n",
      "464/464 [==============================] - 48s 102ms/step - loss: 0.0241 - val_loss: 0.0240\n",
      "Epoch 5/20\n",
      "464/464 [==============================] - 47s 102ms/step - loss: 0.0241 - val_loss: 0.0240\n",
      "Epoch 6/20\n",
      "464/464 [==============================] - 47s 101ms/step - loss: 0.0241 - val_loss: 0.0240\n",
      "Epoch 7/20\n",
      "464/464 [==============================] - 48s 104ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 8/20\n",
      "464/464 [==============================] - 46s 100ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 9/20\n",
      "464/464 [==============================] - 49s 106ms/step - loss: 0.0241 - val_loss: 0.0240\n",
      "Epoch 10/20\n",
      "464/464 [==============================] - 46s 100ms/step - loss: 0.0241 - val_loss: 0.0240\n",
      "Epoch 11/20\n",
      "464/464 [==============================] - 49s 105ms/step - loss: 0.0241 - val_loss: 0.0240\n",
      "Epoch 12/20\n",
      "464/464 [==============================] - 47s 102ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 13/20\n",
      "464/464 [==============================] - 47s 102ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 14/20\n",
      "464/464 [==============================] - 48s 104ms/step - loss: 0.0240 - val_loss: 0.0239\n",
      "Epoch 15/20\n",
      "464/464 [==============================] - 47s 102ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 16/20\n",
      "464/464 [==============================] - 47s 101ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 17/20\n",
      "464/464 [==============================] - 47s 102ms/step - loss: 0.0240 - val_loss: 0.0239\n",
      "Epoch 18/20\n",
      "464/464 [==============================] - 47s 101ms/step - loss: 0.0240 - val_loss: 0.0240\n",
      "Epoch 19/20\n",
      "464/464 [==============================] - 48s 104ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 20/20\n",
      "464/464 [==============================] - 48s 103ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC5rnn_case2_0.2\\assets\n",
      "6 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_7 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(74176, 12, 1) (74176,)\n",
      "Epoch 1/20\n",
      "  1/464 [..............................] - ETA: 43s - loss: 0.0385"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwangwoon\\anaconda3\\envs\\rnn-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464/464 [==============================] - 47s 101ms/step - loss: 0.0253 - val_loss: 0.0251\n",
      "Epoch 2/20\n",
      "464/464 [==============================] - 47s 100ms/step - loss: 0.0253 - val_loss: 0.0251\n",
      "Epoch 3/20\n",
      "464/464 [==============================] - 48s 103ms/step - loss: 0.0253 - val_loss: 0.0251\n",
      "Epoch 4/20\n",
      "464/464 [==============================] - 48s 103ms/step - loss: 0.0253 - val_loss: 0.0251\n",
      "Epoch 5/20\n",
      "464/464 [==============================] - 46s 100ms/step - loss: 0.0253 - val_loss: 0.0251\n",
      "Epoch 6/20\n",
      "464/464 [==============================] - 49s 106ms/step - loss: 0.0253 - val_loss: 0.0251\n",
      "Epoch 7/20\n",
      "464/464 [==============================] - 46s 100ms/step - loss: 0.0253 - val_loss: 0.0250\n",
      "Epoch 8/20\n",
      "464/464 [==============================] - 49s 106ms/step - loss: 0.0253 - val_loss: 0.0251\n",
      "Epoch 9/20\n",
      "464/464 [==============================] - 46s 98ms/step - loss: 0.0253 - val_loss: 0.0251\n",
      "Epoch 10/20\n",
      "464/464 [==============================] - 50s 107ms/step - loss: 0.0253 - val_loss: 0.0251\n",
      "Epoch 11/20\n",
      "464/464 [==============================] - 48s 103ms/step - loss: 0.0253 - val_loss: 0.0250\n",
      "Epoch 12/20\n",
      "464/464 [==============================] - 48s 103ms/step - loss: 0.0253 - val_loss: 0.0251\n",
      "Epoch 13/20\n",
      "464/464 [==============================] - 46s 98ms/step - loss: 0.0253 - val_loss: 0.0251\n",
      "Epoch 14/20\n",
      "464/464 [==============================] - 45s 96ms/step - loss: 0.0253 - val_loss: 0.0250\n",
      "Epoch 15/20\n",
      "464/464 [==============================] - 46s 98ms/step - loss: 0.0253 - val_loss: 0.0250\n",
      "Epoch 16/20\n",
      "464/464 [==============================] - 44s 96ms/step - loss: 0.0253 - val_loss: 0.0251\n",
      "Epoch 17/20\n",
      "464/464 [==============================] - 45s 96ms/step - loss: 0.0253 - val_loss: 0.0250\n",
      "Epoch 18/20\n",
      "464/464 [==============================] - 45s 98ms/step - loss: 0.0253 - val_loss: 0.0251\n",
      "Epoch 19/20\n",
      "464/464 [==============================] - 44s 94ms/step - loss: 0.0253 - val_loss: 0.0250\n",
      "Epoch 20/20\n",
      "464/464 [==============================] - 45s 97ms/step - loss: 0.0253 - val_loss: 0.0250\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC6rnn_case2_0.2\\assets\n",
      "7 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_8 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_8 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(74176, 12, 1) (74176,)\n",
      "Epoch 1/20\n",
      "  1/464 [..............................] - ETA: 50s - loss: 0.0148"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwangwoon\\anaconda3\\envs\\rnn-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464/464 [==============================] - 45s 97ms/step - loss: 0.0237 - val_loss: 0.0236\n",
      "Epoch 2/20\n",
      "464/464 [==============================] - 44s 95ms/step - loss: 0.0236 - val_loss: 0.0236\n",
      "Epoch 3/20\n",
      "464/464 [==============================] - 46s 99ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 4/20\n",
      "464/464 [==============================] - 45s 97ms/step - loss: 0.0236 - val_loss: 0.0236\n",
      "Epoch 5/20\n",
      "464/464 [==============================] - 45s 97ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 6/20\n",
      "464/464 [==============================] - 45s 97ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 7/20\n",
      "464/464 [==============================] - 45s 97ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 8/20\n",
      "464/464 [==============================] - 45s 97ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 9/20\n",
      "464/464 [==============================] - 45s 97ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 10/20\n",
      "464/464 [==============================] - 45s 97ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 11/20\n",
      "464/464 [==============================] - 44s 96ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 12/20\n",
      "464/464 [==============================] - 45s 98ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 13/20\n",
      "464/464 [==============================] - 45s 97ms/step - loss: 0.0236 - val_loss: 0.0236\n",
      "Epoch 14/20\n",
      "464/464 [==============================] - 45s 97ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 15/20\n",
      "464/464 [==============================] - 45s 97ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 16/20\n",
      "464/464 [==============================] - 45s 97ms/step - loss: 0.0236 - val_loss: 0.0236\n",
      "Epoch 17/20\n",
      "464/464 [==============================] - 45s 97ms/step - loss: 0.0236 - val_loss: 0.0236\n",
      "Epoch 18/20\n",
      "464/464 [==============================] - 45s 97ms/step - loss: 0.0236 - val_loss: 0.0236\n",
      "Epoch 19/20\n",
      "464/464 [==============================] - 45s 98ms/step - loss: 0.0236 - val_loss: 0.0236\n",
      "Epoch 20/20\n",
      "464/464 [==============================] - 45s 97ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC7rnn_case2_0.2\\assets\n",
      "8 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_18 (LSTM)              (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_9 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_9 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(74176, 12, 1) (74176,)\n",
      "Epoch 1/20\n",
      "  1/464 [..............................] - ETA: 43s - loss: 0.0255"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwangwoon\\anaconda3\\envs\\rnn-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464/464 [==============================] - 45s 96ms/step - loss: 0.0256 - val_loss: 0.0246\n",
      "Epoch 2/20\n",
      "464/464 [==============================] - 45s 96ms/step - loss: 0.0256 - val_loss: 0.0247\n",
      "Epoch 3/20\n",
      "464/464 [==============================] - 46s 99ms/step - loss: 0.0256 - val_loss: 0.0246\n",
      "Epoch 4/20\n",
      "464/464 [==============================] - 44s 96ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 5/20\n",
      "464/464 [==============================] - 45s 98ms/step - loss: 0.0256 - val_loss: 0.0246\n",
      "Epoch 6/20\n",
      "464/464 [==============================] - 44s 95ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 7/20\n",
      "464/464 [==============================] - 45s 96ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 8/20\n",
      "464/464 [==============================] - 46s 98ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 9/20\n",
      "464/464 [==============================] - 44s 96ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 10/20\n",
      "464/464 [==============================] - 45s 97ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 11/20\n",
      "464/464 [==============================] - 45s 97ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 12/20\n",
      "464/464 [==============================] - 45s 96ms/step - loss: 0.0256 - val_loss: 0.0246\n",
      "Epoch 13/20\n",
      "464/464 [==============================] - 45s 98ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 14/20\n",
      "464/464 [==============================] - 45s 97ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 15/20\n",
      "464/464 [==============================] - 44s 95ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 16/20\n",
      "464/464 [==============================] - 45s 96ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 17/20\n",
      "464/464 [==============================] - 45s 96ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 18/20\n",
      "464/464 [==============================] - 45s 96ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 19/20\n",
      "464/464 [==============================] - 45s 97ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 20/20\n",
      "464/464 [==============================] - 44s 96ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC8rnn_case2_0.2\\assets\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:1\"):\n",
    "    for mec_index in range(train_dataset.shape[2]): # mecs만큼 반복\n",
    "        print(mec_index,'mec 학습중 ...')\n",
    "        rnn_model = get_model()\n",
    "        print(rnn_model.summary())\n",
    "        print(X_train[mec_index].shape, Y_train[mec_index].shape)\n",
    "        rnn_model.fit(X_train[mec_index], Y_train[mec_index], epochs=20, validation_split=0.2, verbose=1, batch_size = 128)\n",
    "        rnn_model.save('./rnn_models/MEC'+str(mec_index)+'rnn_'+file_path[-9:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOpUcXClG8ECcBkwzfPGTbR",
   "mount_file_id": "1ZHgDD_jTvpgXzoRBbhcNUoQwM3bh22wU",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rnn-gpu",
   "language": "python",
   "name": "rnn-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
