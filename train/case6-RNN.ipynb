{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1690642228271,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "C2y_S3-nJR4w",
    "outputId": "f5a19309-e562-4226-8b3b-fc8fbfe55488"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "input gradual degree 5/15/50 :  50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300, 16, 128)\n",
      "['train0.png', 'train1.png', 'train2.png', 'train3.png', 'train4.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import natsort\n",
    "from PIL import Image\n",
    "\n",
    "gradual = input('input gradual degree 5/15/50 : ')\n",
    "\n",
    "file_path = './rand_grad'+gradual+'_2k'\n",
    "file_list = os.listdir(file_path)\n",
    "file_list = natsort.natsorted(file_list, key=None, reverse=False, alg=0)\n",
    "\n",
    "num_of_files = len(file_list)\n",
    "\n",
    "# Assuming all images have the same height and width\n",
    "first_image = Image.open(os.path.join(file_path, file_list[0]))\n",
    "height, width = np.array(first_image).shape\n",
    "\n",
    "# Create an empty NumPy array to store the images\n",
    "image_array = np.empty((num_of_files, height, width))\n",
    "\n",
    "# Iterate through the file list and load images\n",
    "for i, file_name in enumerate(file_list):\n",
    "    image = Image.open(os.path.join(file_path, file_name))\n",
    "    image_array[i] = np.array(image)\n",
    "\n",
    "# image_array now contains the images as NumPy arrays\n",
    "print(image_array.shape)  # (num_of_files, height, width)\n",
    "print(file_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1690642228271,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "xEldMqsNUzZJ",
    "outputId": "d7b6866c-df6d-4a53-dbea-4969724a2324"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train0.png\n",
      "train1.png\n",
      "train2.png\n",
      "train3.png\n",
      "train4.png\n",
      "train5.png\n",
      "train6.png\n",
      "train7.png\n",
      "train8.png\n",
      "train9.png\n",
      "train10.png\n",
      "train11.png\n",
      "train12.png\n",
      "\n",
      "train1.png\n",
      "train2.png\n",
      "train3.png\n",
      "train4.png\n",
      "train5.png\n",
      "train6.png\n",
      "train7.png\n",
      "train8.png\n",
      "train9.png\n",
      "train10.png\n",
      "train11.png\n",
      "train12.png\n",
      "train13.png\n",
      "\n",
      "(1288, 13, 16, 128)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "window_size = int(input())\n",
    "num_of_frames = window_size+1  # Specify the desired number of frames\n",
    "\n",
    "# Assuming all images have the same height and width\n",
    "first_image = Image.open(os.path.join(file_path, file_list[0]))\n",
    "height, width = np.array(first_image).shape[:2]\n",
    "\n",
    "# Create an empty NumPy array to store the images\n",
    "dataset = np.empty((num_of_files-num_of_frames+1, num_of_frames, height, width))\n",
    "\n",
    "# Iterate through the file list and load images\n",
    "for i in range(num_of_files-num_of_frames+1):\n",
    "    frame_images = file_list[i : i+num_of_frames]\n",
    "    for j, file_name in enumerate(frame_images):\n",
    "        if i < 2:\n",
    "            print(file_name)\n",
    "        image = Image.open(os.path.join(file_path, file_name))\n",
    "        dataset[i, j] = np.array(image)\n",
    "    if i < 2:\n",
    "        print()\n",
    "\n",
    "# dataset now contains the images bound into frames\n",
    "print(dataset.shape)  # (num_of_files // num_of_frames, num_of_frames, height, width)12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1690642228271,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "8TrYB66sX_yI",
    "outputId": "2671a939-ca7d-496d-b750-d589adceb1d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1288, 13, 16, 128, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a channel dimension since the images are grayscale.\n",
    "dataset = np.expand_dims(dataset, axis=-1)\n",
    "dataset.shape #(num_of_samples, frames, height, width, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1690642228272,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "x8319gfKUkes",
    "outputId": "6c8e4095-c9f5-4cd6-bd53-9b1f0c44378c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1159, 13, 16, 128, 1) (129, 13, 16, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into train and validation sets using indexing to optimize memory.\n",
    "indexes = np.arange(dataset.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "train_index = indexes[: int(0.9 * dataset.shape[0])]\n",
    "val_index = indexes[int(0.9 * dataset.shape[0]) :]\n",
    "train_dataset = dataset[train_index]\n",
    "val_dataset = dataset[val_index]\n",
    "\n",
    "# Normalize the data to the 0-1 range.\n",
    "train_dataset = train_dataset / 255\n",
    "val_dataset = val_dataset / 255\n",
    "\n",
    "print(train_dataset.shape, val_dataset.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "bbydufV0bBt2"
   },
   "source": [
    "# RNN\n",
    "1. 각 MEC 당 128 input -> 128개 output.\n",
    "2. 과거 12개 관찰."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 8097,
     "status": "ok",
     "timestamp": 1690642236366,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "RHWKfIYubBt3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "window_size  = 12\n",
    "\n",
    "def create_shifted_frames(data, mec_index): # data = (frames, mecs, movieId, gray_scale)\n",
    "    tmp_data = data[:,mec_index,:,:]\n",
    "    tmp_data = np.squeeze(tmp_data)\n",
    "    tmp_data = tmp_data.transpose()\n",
    "\n",
    "    return tmp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1777,
     "status": "ok",
     "timestamp": 1690642238140,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "CCoGOWQ-bBt3",
    "outputId": "0c22e886-8587-4cab-d196-bc559497625e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 1, 100)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 1, 1)             101       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    inputs = layers.Input(shape=(window_size,1))\n",
    "    encoder = layers.LSTM(100, activation=\"relu\", return_sequences=False)(inputs)\n",
    "    repeat = layers.RepeatVector(1)(encoder)\n",
    "    decoder = layers.LSTM(100, activation='relu', return_sequences=True)(repeat)\n",
    "    outputs = layers.TimeDistributed(layers.Dense(1))(decoder)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    return model\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "#observe_mec_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1158  train ...\n",
      "no observe mec index\n",
      "15  번째 mec 학습중 ...\n",
      "frame shape :  (128, 13)\n",
      "0  movie  train ...  (13,)\n",
      "1  movie  train ...  (13,)\n",
      "2  movie  train ...  (13,)\n",
      "3  movie  train ...  (13,)\n",
      "4  movie  train ...  (13,)\n",
      "5  movie  train ...  (13,)\n",
      "6  movie  train ...  (13,)\n",
      "7  movie  train ...  (13,)\n",
      "8  movie  train ...  (13,)\n",
      "9  movie  train ...  (13,)\n",
      "10  movie  train ...  (13,)\n",
      "11  movie  train ...  (13,)\n",
      "12  movie  train ...  (13,)\n",
      "13  movie  train ...  (13,)\n",
      "14  movie  train ...  (13,)\n",
      "15  movie  train ...  (13,)\n",
      "16  movie  train ...  (13,)\n",
      "17  movie  train ...  (13,)\n",
      "18  movie  train ...  (13,)\n",
      "19  movie  train ...  (13,)\n",
      "20  movie  train ...  (13,)\n",
      "21  movie  train ...  (13,)\n",
      "22  movie  train ...  (13,)\n",
      "23  movie  train ...  (13,)\n",
      "24  movie  train ...  (13,)\n",
      "25  movie  train ...  (13,)\n",
      "26  movie  train ...  (13,)\n",
      "27  movie  train ...  (13,)\n",
      "28  movie  train ...  (13,)\n",
      "29  movie  train ...  (13,)\n",
      "30  movie  train ...  (13,)\n",
      "31  movie  train ...  (13,)\n",
      "32  movie  train ...  (13,)\n",
      "33  movie  train ...  (13,)\n",
      "34  movie  train ...  (13,)\n",
      "35  movie  train ...  (13,)\n",
      "36  movie  train ...  (13,)\n",
      "37  movie  train ...  (13,)\n",
      "38  movie  train ...  (13,)\n",
      "39  movie  train ...  (13,)\n",
      "40  movie  train ...  (13,)\n",
      "41  movie  train ...  (13,)\n",
      "42  movie  train ...  (13,)\n",
      "43  movie  train ...  (13,)\n",
      "44  movie  train ...  (13,)\n",
      "45  movie  train ...  (13,)\n",
      "46  movie  train ...  (13,)\n",
      "47  movie  train ...  (13,)\n",
      "48  movie  train ...  (13,)\n",
      "49  movie  train ...  (13,)\n",
      "50  movie  train ...  (13,)\n",
      "51  movie  train ...  (13,)\n",
      "52  movie  train ...  (13,)\n",
      "53  movie  train ...  (13,)\n",
      "54  movie  train ...  (13,)\n",
      "55  movie  train ...  (13,)\n",
      "56  movie  train ...  (13,)\n",
      "57  movie  train ...  (13,)\n",
      "58  movie  train ...  (13,)\n",
      "59  movie  train ...  (13,)\n",
      "60  movie  train ...  (13,)\n",
      "61  movie  train ...  (13,)\n",
      "62  movie  train ...  (13,)\n",
      "63  movie  train ...  (13,)\n",
      "64  movie  train ...  (13,)\n",
      "65  movie  train ...  (13,)\n",
      "66  movie  train ...  (13,)\n",
      "67  movie  train ...  (13,)\n",
      "68  movie  train ...  (13,)\n",
      "69  movie  train ...  (13,)\n",
      "70  movie  train ...  (13,)\n",
      "71  movie  train ...  (13,)\n",
      "72  movie  train ...  (13,)\n",
      "73  movie  train ...  (13,)\n",
      "74  movie  train ...  (13,)\n",
      "75  movie  train ...  (13,)\n",
      "76  movie  train ...  (13,)\n",
      "77  movie  train ...  (13,)\n",
      "78  movie  train ...  (13,)\n",
      "79  movie  train ...  (13,)\n",
      "80  movie  train ...  (13,)\n",
      "81  movie  train ...  (13,)\n",
      "82  movie  train ...  (13,)\n",
      "83  movie  train ...  (13,)\n",
      "84  movie  train ...  (13,)\n",
      "85  movie  train ...  (13,)\n",
      "86  movie  train ...  (13,)\n",
      "87  movie  train ...  (13,)\n",
      "88  movie  train ...  (13,)\n",
      "89  movie  train ...  (13,)\n",
      "90  movie  train ...  (13,)\n",
      "91  movie  train ...  (13,)\n",
      "92  movie  train ...  (13,)\n",
      "93  movie  train ...  (13,)\n",
      "94  movie  train ...  (13,)\n",
      "95  movie  train ...  (13,)\n",
      "96  movie  train ...  (13,)\n",
      "97  movie  train ...  (13,)\n",
      "98  movie  train ...  (13,)\n",
      "99  movie  train ...  (13,)\n",
      "100  movie  train ...  (13,)\n",
      "101  movie  train ...  (13,)\n",
      "102  movie  train ...  (13,)\n",
      "103  movie  train ...  (13,)\n",
      "104  movie  train ...  (13,)\n",
      "105  movie  train ...  (13,)\n",
      "106  movie  train ...  (13,)\n",
      "107  movie  train ...  (13,)\n",
      "108  movie  train ...  (13,)\n",
      "109  movie  train ...  (13,)\n",
      "110  movie  train ...  (13,)\n",
      "111  movie  train ...  (13,)\n",
      "112  movie  train ...  (13,)\n",
      "113  movie  train ...  (13,)\n",
      "114  movie  train ...  (13,)\n",
      "115  movie  train ...  (13,)\n",
      "116  movie  train ...  (13,)\n",
      "117  movie  train ...  (13,)\n",
      "118  movie  train ...  (13,)\n",
      "119  movie  train ...  (13,)\n",
      "120  movie  train ...  (13,)\n",
      "121  movie  train ...  (13,)\n",
      "122  movie  train ...  (13,)\n",
      "123  movie  train ...  (13,)\n",
      "124  movie  train ...  (13,)\n",
      "125  movie  train ...  (13,)\n",
      "126  movie  train ...  (13,)\n",
      "127  movie  train ...  (13,)\n",
      "(16, 148352, 12, 1) (16, 148352)\n"
     ]
    }
   ],
   "source": [
    "X_train = [[] for _ in range(train_dataset.shape[2])]\n",
    "Y_train = [[] for _ in range(train_dataset.shape[2])]\n",
    "for day_index, oneday_dataset in enumerate(train_dataset):\n",
    "    for mec_index in range(oneday_dataset.shape[1]):\n",
    "        clear_output(wait=True)\n",
    "        print(day_index, ' train ...')\n",
    "        \n",
    "        try:\n",
    "            if mec_index != observe_mec_index:\n",
    "                continue\n",
    "        except:\n",
    "            print('no observe mec index')\n",
    "\n",
    "        print(mec_index,' 번째 mec 학습중 ...')\n",
    "        frame_dataset = create_shifted_frames(oneday_dataset, mec_index)\n",
    "        print('frame shape : ', frame_dataset.shape)\n",
    "\n",
    "        X,Y = np.empty((1,12,1)), np.empty((1))\n",
    "        for movieId_index, movieId in enumerate(frame_dataset):\n",
    "            print(movieId_index, ' movie  train ... ', movieId.shape)\n",
    "            x = movieId[:-1]\n",
    "            x = np.array([[x[i] for i in range(j,j+window_size)] for j in range(len(x)-window_size+1)])\n",
    "            y = movieId[window_size:]\n",
    "            x = np.expand_dims(x, axis=-1)\n",
    "            #print('final X,Y shape : ',  x.shape, y.shape)\n",
    "            X = np.append(X,x, axis=0)\n",
    "            Y = np.append(Y,y, axis=0)\n",
    "\n",
    "        X = np.delete(X, 0, axis=0)\n",
    "        Y = np.delete(Y, 0, axis=0)\n",
    "        try:\n",
    "            X_train[mec_index].extend(X)\n",
    "            Y_train[mec_index].extend(Y)\n",
    "        except:\n",
    "            X_train[mec_index] = np.append(X_train[mec_index], X, axis=0)\n",
    "            Y_train[mec_index] = np.append(Y_train[mec_index], Y, axis=0)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_1 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(148352, 12, 1) (148352,)\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwangwoon\\anaconda3\\envs\\rnn-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "928/928 [==============================] - 83s 88ms/step - loss: 0.0703 - val_loss: 0.0663\n",
      "Epoch 2/20\n",
      "928/928 [==============================] - 83s 90ms/step - loss: 0.0662 - val_loss: 0.0666\n",
      "Epoch 3/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0661 - val_loss: 0.0664\n",
      "Epoch 4/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0661 - val_loss: 0.0663\n",
      "Epoch 5/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0661 - val_loss: 0.0663\n",
      "Epoch 6/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0666\n",
      "Epoch 7/20\n",
      "928/928 [==============================] - 82s 88ms/step - loss: 0.0660 - val_loss: 0.0665\n",
      "Epoch 8/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0660 - val_loss: 0.0663\n",
      "Epoch 9/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0663\n",
      "Epoch 10/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0663\n",
      "Epoch 11/20\n",
      "928/928 [==============================] - 81s 88ms/step - loss: 0.0659 - val_loss: 0.0663\n",
      "Epoch 12/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0664\n",
      "Epoch 13/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0659 - val_loss: 0.0663\n",
      "Epoch 14/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0659 - val_loss: 0.0663\n",
      "Epoch 15/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0659 - val_loss: 0.0663\n",
      "Epoch 16/20\n",
      "928/928 [==============================] - 79s 86ms/step - loss: 0.0659 - val_loss: 0.0663\n",
      "Epoch 17/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0659 - val_loss: 0.0663\n",
      "Epoch 18/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0659 - val_loss: 0.0663\n",
      "Epoch 19/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0659 - val_loss: 0.0663\n",
      "Epoch 20/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0659 - val_loss: 0.0663\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC0rnn_rand_grad50_2k\\assets\n",
      "1 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_2 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(148352, 12, 1) (148352,)\n",
      "Epoch 1/20\n",
      "  1/928 [..............................] - ETA: 1:27 - loss: 0.3486"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwangwoon\\anaconda3\\envs\\rnn-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0715 - val_loss: 0.0657\n",
      "Epoch 2/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0664 - val_loss: 0.0655\n",
      "Epoch 3/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0663 - val_loss: 0.0657\n",
      "Epoch 4/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0663 - val_loss: 0.0655\n",
      "Epoch 5/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0663 - val_loss: 0.0661\n",
      "Epoch 6/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0662 - val_loss: 0.0661\n",
      "Epoch 7/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0662 - val_loss: 0.0658\n",
      "Epoch 8/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0663 - val_loss: 0.0656\n",
      "Epoch 9/20\n",
      "928/928 [==============================] - 78s 85ms/step - loss: 0.0662 - val_loss: 0.0655\n",
      "Epoch 10/20\n",
      "928/928 [==============================] - 78s 84ms/step - loss: 0.0662 - val_loss: 0.0657\n",
      "Epoch 11/20\n",
      "928/928 [==============================] - 78s 84ms/step - loss: 0.0662 - val_loss: 0.0656\n",
      "Epoch 12/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0662 - val_loss: 0.0661\n",
      "Epoch 13/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0662 - val_loss: 0.0656\n",
      "Epoch 14/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0662 - val_loss: 0.0656\n",
      "Epoch 15/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0662 - val_loss: 0.0656\n",
      "Epoch 16/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0662 - val_loss: 0.0658\n",
      "Epoch 17/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0662 - val_loss: 0.0655\n",
      "Epoch 18/20\n",
      "928/928 [==============================] - 79s 86ms/step - loss: 0.0662 - val_loss: 0.0656\n",
      "Epoch 19/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0662 - val_loss: 0.0655\n",
      "Epoch 20/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0662 - val_loss: 0.0656\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC1rnn_rand_grad50_2k\\assets\n",
      "2 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_3 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(148352, 12, 1) (148352,)\n",
      "Epoch 1/20\n",
      "  1/928 [..............................] - ETA: 1:29 - loss: 0.3329"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwangwoon\\anaconda3\\envs\\rnn-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "928/928 [==============================] - 78s 84ms/step - loss: 0.0708 - val_loss: 0.0663\n",
      "Epoch 2/20\n",
      "928/928 [==============================] - 78s 84ms/step - loss: 0.0664 - val_loss: 0.0660\n",
      "Epoch 3/20\n",
      "928/928 [==============================] - 78s 84ms/step - loss: 0.0663 - val_loss: 0.0676\n",
      "Epoch 4/20\n",
      "928/928 [==============================] - 78s 84ms/step - loss: 0.0663 - val_loss: 0.0661\n",
      "Epoch 5/20\n",
      "928/928 [==============================] - 78s 85ms/step - loss: 0.0662 - val_loss: 0.0660\n",
      "Epoch 6/20\n",
      "928/928 [==============================] - 78s 85ms/step - loss: 0.0662 - val_loss: 0.0662\n",
      "Epoch 7/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0662 - val_loss: 0.0660\n",
      "Epoch 8/20\n",
      "928/928 [==============================] - 78s 84ms/step - loss: 0.0662 - val_loss: 0.0661\n",
      "Epoch 9/20\n",
      "928/928 [==============================] - 78s 84ms/step - loss: 0.0662 - val_loss: 0.0660\n",
      "Epoch 10/20\n",
      "928/928 [==============================] - 78s 84ms/step - loss: 0.0661 - val_loss: 0.0661\n",
      "Epoch 11/20\n",
      "928/928 [==============================] - 78s 84ms/step - loss: 0.0662 - val_loss: 0.0662\n",
      "Epoch 12/20\n",
      "928/928 [==============================] - 78s 84ms/step - loss: 0.0662 - val_loss: 0.0661\n",
      "Epoch 13/20\n",
      "928/928 [==============================] - 78s 84ms/step - loss: 0.0661 - val_loss: 0.0660\n",
      "Epoch 14/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0661 - val_loss: 0.0660\n",
      "Epoch 15/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0661 - val_loss: 0.0660\n",
      "Epoch 16/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0661 - val_loss: 0.0661\n",
      "Epoch 17/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0661 - val_loss: 0.0660\n",
      "Epoch 18/20\n",
      "928/928 [==============================] - 78s 85ms/step - loss: 0.0661 - val_loss: 0.0660\n",
      "Epoch 19/20\n",
      "928/928 [==============================] - 78s 85ms/step - loss: 0.0661 - val_loss: 0.0660\n",
      "Epoch 20/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0661 - val_loss: 0.0661\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC2rnn_rand_grad50_2k\\assets\n",
      "3 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_4 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(148352, 12, 1) (148352,)\n",
      "Epoch 1/20\n",
      "  1/928 [..............................] - ETA: 1:30 - loss: 0.2802"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwangwoon\\anaconda3\\envs\\rnn-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0710 - val_loss: 0.0666\n",
      "Epoch 2/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0663 - val_loss: 0.0661\n",
      "Epoch 3/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0662 - val_loss: 0.0661\n",
      "Epoch 4/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0662 - val_loss: 0.0661\n",
      "Epoch 5/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0661 - val_loss: 0.0660\n",
      "Epoch 6/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0662 - val_loss: 0.0660\n",
      "Epoch 7/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0661 - val_loss: 0.0661\n",
      "Epoch 8/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0661 - val_loss: 0.0660\n",
      "Epoch 9/20\n",
      "928/928 [==============================] - 79s 86ms/step - loss: 0.0661 - val_loss: 0.0661\n",
      "Epoch 10/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0661 - val_loss: 0.0663\n",
      "Epoch 11/20\n",
      "928/928 [==============================] - 79s 86ms/step - loss: 0.0661 - val_loss: 0.0660\n",
      "Epoch 12/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0661 - val_loss: 0.0661\n",
      "Epoch 13/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0661 - val_loss: 0.0661\n",
      "Epoch 14/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0662\n",
      "Epoch 15/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "Epoch 16/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "Epoch 17/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0660\n",
      "Epoch 18/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "Epoch 19/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "Epoch 20/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC3rnn_rand_grad50_2k\\assets\n",
      "4 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_5 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(148352, 12, 1) (148352,)\n",
      "Epoch 1/20\n",
      "  1/928 [..............................] - ETA: 1:34 - loss: 0.2936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwangwoon\\anaconda3\\envs\\rnn-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0710 - val_loss: 0.0662\n",
      "Epoch 2/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0663 - val_loss: 0.0661\n",
      "Epoch 3/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0662 - val_loss: 0.0665\n",
      "Epoch 4/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0662 - val_loss: 0.0661\n",
      "Epoch 5/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0661 - val_loss: 0.0661\n",
      "Epoch 6/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0661 - val_loss: 0.0662\n",
      "Epoch 7/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "Epoch 8/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0661 - val_loss: 0.0661\n",
      "Epoch 9/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "Epoch 10/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0664\n",
      "Epoch 11/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "Epoch 12/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "Epoch 13/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "Epoch 14/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0660 - val_loss: 0.0666\n",
      "Epoch 15/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "Epoch 16/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "Epoch 17/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "Epoch 18/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0660 - val_loss: 0.0662\n",
      "Epoch 19/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "Epoch 20/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC4rnn_rand_grad50_2k\\assets\n",
      "5 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_6 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(148352, 12, 1) (148352,)\n",
      "Epoch 1/20\n",
      "  1/928 [..............................] - ETA: 1:35 - loss: 0.3166"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwangwoon\\anaconda3\\envs\\rnn-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0712 - val_loss: 0.0668\n",
      "Epoch 2/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0661 - val_loss: 0.0667\n",
      "Epoch 3/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0670\n",
      "Epoch 4/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0659 - val_loss: 0.0667\n",
      "Epoch 5/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0659 - val_loss: 0.0665\n",
      "Epoch 6/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0659 - val_loss: 0.0666\n",
      "Epoch 7/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0659 - val_loss: 0.0665\n",
      "Epoch 8/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0659 - val_loss: 0.0665\n",
      "Epoch 9/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0658 - val_loss: 0.0666\n",
      "Epoch 10/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0658 - val_loss: 0.0668\n",
      "Epoch 11/20\n",
      "928/928 [==============================] - 79s 86ms/step - loss: 0.0658 - val_loss: 0.0665\n",
      "Epoch 12/20\n",
      "928/928 [==============================] - 79s 86ms/step - loss: 0.0658 - val_loss: 0.0668\n",
      "Epoch 13/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0658 - val_loss: 0.0665\n",
      "Epoch 14/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0658 - val_loss: 0.0665\n",
      "Epoch 15/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0658 - val_loss: 0.0665\n",
      "Epoch 16/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0658 - val_loss: 0.0668\n",
      "Epoch 17/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0658 - val_loss: 0.0665\n",
      "Epoch 18/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0658 - val_loss: 0.0665\n",
      "Epoch 19/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0658 - val_loss: 0.0665\n",
      "Epoch 20/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0658 - val_loss: 0.0665\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC5rnn_rand_grad50_2k\\assets\n",
      "6 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_7 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(148352, 12, 1) (148352,)\n",
      "Epoch 1/20\n",
      "  1/928 [..............................] - ETA: 1:28 - loss: 0.3127"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwangwoon\\anaconda3\\envs\\rnn-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0705 - val_loss: 0.0667\n",
      "Epoch 2/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0660 - val_loss: 0.0666\n",
      "Epoch 3/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0660 - val_loss: 0.0673\n",
      "Epoch 4/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0660 - val_loss: 0.0668\n",
      "Epoch 5/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0659 - val_loss: 0.0666\n",
      "Epoch 6/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0659 - val_loss: 0.0666\n",
      "Epoch 7/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0659 - val_loss: 0.0666\n",
      "Epoch 8/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0658 - val_loss: 0.0667\n",
      "Epoch 9/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0658 - val_loss: 0.0667\n",
      "Epoch 10/20\n",
      "928/928 [==============================] - 79s 86ms/step - loss: 0.0658 - val_loss: 0.0668\n",
      "Epoch 11/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0658 - val_loss: 0.0668\n",
      "Epoch 12/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0658 - val_loss: 0.0666\n",
      "Epoch 13/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0658 - val_loss: 0.0667\n",
      "Epoch 14/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0658 - val_loss: 0.0668\n",
      "Epoch 15/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0658 - val_loss: 0.0667\n",
      "Epoch 16/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0658 - val_loss: 0.0667\n",
      "Epoch 17/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0658 - val_loss: 0.0667\n",
      "Epoch 18/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0658 - val_loss: 0.0667\n",
      "Epoch 19/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0658 - val_loss: 0.0667\n",
      "Epoch 20/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0658 - val_loss: 0.0667\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC6rnn_rand_grad50_2k\\assets\n",
      "7 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_8 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_8 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(148352, 12, 1) (148352,)\n",
      "Epoch 1/20\n",
      "  1/928 [..............................] - ETA: 1:28 - loss: 0.3704"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwangwoon\\anaconda3\\envs\\rnn-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0712 - val_loss: 0.0681\n",
      "Epoch 2/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0662 - val_loss: 0.0662\n",
      "Epoch 3/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0660 - val_loss: 0.0662\n",
      "Epoch 4/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0662\n",
      "Epoch 5/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "Epoch 6/20\n",
      "928/928 [==============================] - 81s 88ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "Epoch 7/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0659 - val_loss: 0.0661\n",
      "Epoch 8/20\n",
      "928/928 [==============================] - 84s 91ms/step - loss: 0.0659 - val_loss: 0.0661\n",
      "Epoch 9/20\n",
      "928/928 [==============================] - 84s 90ms/step - loss: 0.0659 - val_loss: 0.0664\n",
      "Epoch 10/20\n",
      "928/928 [==============================] - 85s 91ms/step - loss: 0.0659 - val_loss: 0.0661\n",
      "Epoch 11/20\n",
      "928/928 [==============================] - 84s 90ms/step - loss: 0.0659 - val_loss: 0.0662\n",
      "Epoch 12/20\n",
      "928/928 [==============================] - 83s 89ms/step - loss: 0.0658 - val_loss: 0.0663\n",
      "Epoch 13/20\n",
      "928/928 [==============================] - 84s 91ms/step - loss: 0.0658 - val_loss: 0.0661\n",
      "Epoch 14/20\n",
      "928/928 [==============================] - 82s 88ms/step - loss: 0.0659 - val_loss: 0.0662\n",
      "Epoch 15/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0658 - val_loss: 0.0662\n",
      "Epoch 16/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0658 - val_loss: 0.0661\n",
      "Epoch 17/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0659 - val_loss: 0.0661\n",
      "Epoch 18/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0658 - val_loss: 0.0661\n",
      "Epoch 19/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0658 - val_loss: 0.0661\n",
      "Epoch 20/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0658 - val_loss: 0.0664\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC7rnn_rand_grad50_2k\\assets\n",
      "8 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_18 (LSTM)              (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_9 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_9 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(148352, 12, 1) (148352,)\n",
      "Epoch 1/20\n",
      "  1/928 [..............................] - ETA: 1:31 - loss: 0.3204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwangwoon\\anaconda3\\envs\\rnn-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0710 - val_loss: 0.0666\n",
      "Epoch 2/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0663 - val_loss: 0.0662\n",
      "Epoch 3/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0663 - val_loss: 0.0660\n",
      "Epoch 4/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0663 - val_loss: 0.0660\n",
      "Epoch 5/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0663 - val_loss: 0.0661\n",
      "Epoch 6/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0662 - val_loss: 0.0660\n",
      "Epoch 7/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0662 - val_loss: 0.0660\n",
      "Epoch 8/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0662 - val_loss: 0.0665\n",
      "Epoch 9/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0662 - val_loss: 0.0660\n",
      "Epoch 10/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0662 - val_loss: 0.0660\n",
      "Epoch 11/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0662 - val_loss: 0.0660\n",
      "Epoch 12/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0662 - val_loss: 0.0660\n",
      "Epoch 13/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0662 - val_loss: 0.0661\n",
      "Epoch 14/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0662 - val_loss: 0.0660\n",
      "Epoch 15/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0662 - val_loss: 0.0660\n",
      "Epoch 16/20\n",
      "928/928 [==============================] - 79s 86ms/step - loss: 0.0662 - val_loss: 0.0660\n",
      "Epoch 17/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0661 - val_loss: 0.0660\n",
      "Epoch 18/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0661 - val_loss: 0.0661\n",
      "Epoch 19/20\n",
      "928/928 [==============================] - 79s 86ms/step - loss: 0.0661 - val_loss: 0.0660\n",
      "Epoch 20/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0661 - val_loss: 0.0660\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC8rnn_rand_grad50_2k\\assets\n",
      "9 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_20 (LSTM)              (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_10 (RepeatVec  (None, 1, 100)           0         \n",
      " tor)                                                            \n",
      "                                                                 \n",
      " lstm_21 (LSTM)              (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_10 (TimeDi  (None, 1, 1)             101       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(148352, 12, 1) (148352,)\n",
      "Epoch 1/20\n",
      "  1/928 [..............................] - ETA: 1:28 - loss: 0.3066"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwangwoon\\anaconda3\\envs\\rnn-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0709 - val_loss: 0.0655\n",
      "Epoch 2/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0663 - val_loss: 0.0657\n",
      "Epoch 3/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0662 - val_loss: 0.0655\n",
      "Epoch 4/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0662 - val_loss: 0.0654\n",
      "Epoch 5/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0662 - val_loss: 0.0657\n",
      "Epoch 6/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0661 - val_loss: 0.0654\n",
      "Epoch 7/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0661 - val_loss: 0.0654\n",
      "Epoch 8/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0661 - val_loss: 0.0653\n",
      "Epoch 9/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0661 - val_loss: 0.0658\n",
      "Epoch 10/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0660 - val_loss: 0.0654\n",
      "Epoch 11/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0656\n",
      "Epoch 12/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0653\n",
      "Epoch 13/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0653\n",
      "Epoch 14/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0653\n",
      "Epoch 15/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0660 - val_loss: 0.0653\n",
      "Epoch 16/20\n",
      "928/928 [==============================] - 79s 86ms/step - loss: 0.0660 - val_loss: 0.0654\n",
      "Epoch 17/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0653\n",
      "Epoch 18/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0659\n",
      "Epoch 19/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0660 - val_loss: 0.0653\n",
      "Epoch 20/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0653\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC9rnn_rand_grad50_2k\\assets\n",
      "10 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_11 (RepeatVec  (None, 1, 100)           0         \n",
      " tor)                                                            \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_11 (TimeDi  (None, 1, 1)             101       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(148352, 12, 1) (148352,)\n",
      "Epoch 1/20\n",
      "  1/928 [..............................] - ETA: 1:28 - loss: 0.3361"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwangwoon\\anaconda3\\envs\\rnn-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0713 - val_loss: 0.0664\n",
      "Epoch 2/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0662 - val_loss: 0.0660\n",
      "Epoch 3/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0661 - val_loss: 0.0660\n",
      "Epoch 4/20\n",
      "928/928 [==============================] - 79s 86ms/step - loss: 0.0661 - val_loss: 0.0660\n",
      "Epoch 5/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "Epoch 6/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0660 - val_loss: 0.0660\n",
      "Epoch 7/20\n",
      "928/928 [==============================] - 79s 86ms/step - loss: 0.0660 - val_loss: 0.0660\n",
      "Epoch 8/20\n",
      "928/928 [==============================] - 79s 86ms/step - loss: 0.0660 - val_loss: 0.0660\n",
      "Epoch 9/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0663\n",
      "Epoch 10/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "Epoch 11/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0662\n",
      "Epoch 12/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0659 - val_loss: 0.0660\n",
      "Epoch 13/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0660 - val_loss: 0.0660\n",
      "Epoch 14/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0659 - val_loss: 0.0660\n",
      "Epoch 15/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0659 - val_loss: 0.0660\n",
      "Epoch 16/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0659 - val_loss: 0.0661\n",
      "Epoch 17/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0659 - val_loss: 0.0663\n",
      "Epoch 18/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0659 - val_loss: 0.0660\n",
      "Epoch 19/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0659 - val_loss: 0.0660\n",
      "Epoch 20/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0659 - val_loss: 0.0660\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC10rnn_rand_grad50_2k\\assets\n",
      "11 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_24 (LSTM)              (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_12 (RepeatVec  (None, 1, 100)           0         \n",
      " tor)                                                            \n",
      "                                                                 \n",
      " lstm_25 (LSTM)              (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_12 (TimeDi  (None, 1, 1)             101       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(148352, 12, 1) (148352,)\n",
      "Epoch 1/20\n",
      "  1/928 [..............................] - ETA: 1:27 - loss: 0.3056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwangwoon\\anaconda3\\envs\\rnn-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0721 - val_loss: 0.0661\n",
      "Epoch 2/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0662 - val_loss: 0.0662\n",
      "Epoch 3/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0663 - val_loss: 0.0662\n",
      "Epoch 4/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0662 - val_loss: 0.0661\n",
      "Epoch 5/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0661 - val_loss: 0.0660\n",
      "Epoch 6/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0661 - val_loss: 0.0663\n",
      "Epoch 7/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0661 - val_loss: 0.0662\n",
      "Epoch 8/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0661 - val_loss: 0.0663\n",
      "Epoch 9/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0661 - val_loss: 0.0660\n",
      "Epoch 10/20\n",
      "928/928 [==============================] - 81s 88ms/step - loss: 0.0660 - val_loss: 0.0662\n",
      "Epoch 11/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0660 - val_loss: 0.0660\n",
      "Epoch 12/20\n",
      "928/928 [==============================] - 82s 88ms/step - loss: 0.0660 - val_loss: 0.0660\n",
      "Epoch 13/20\n",
      "928/928 [==============================] - 82s 88ms/step - loss: 0.0660 - val_loss: 0.0660\n",
      "Epoch 14/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0660 - val_loss: 0.0660\n",
      "Epoch 15/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0660 - val_loss: 0.0660\n",
      "Epoch 16/20\n",
      "928/928 [==============================] - 82s 88ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "Epoch 17/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "Epoch 18/20\n",
      "928/928 [==============================] - 82s 88ms/step - loss: 0.0660 - val_loss: 0.0660\n",
      "Epoch 19/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0660 - val_loss: 0.0660\n",
      "Epoch 20/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0660 - val_loss: 0.0660\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC11rnn_rand_grad50_2k\\assets\n",
      "12 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_26 (LSTM)              (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_13 (RepeatVec  (None, 1, 100)           0         \n",
      " tor)                                                            \n",
      "                                                                 \n",
      " lstm_27 (LSTM)              (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_13 (TimeDi  (None, 1, 1)             101       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(148352, 12, 1) (148352,)\n",
      "Epoch 1/20\n",
      "  1/928 [..............................] - ETA: 1:31 - loss: 0.3156"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwangwoon\\anaconda3\\envs\\rnn-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0706 - val_loss: 0.0662\n",
      "Epoch 2/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0661 - val_loss: 0.0667\n",
      "Epoch 3/20\n",
      "928/928 [==============================] - 81s 88ms/step - loss: 0.0661 - val_loss: 0.0664\n",
      "Epoch 4/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "Epoch 5/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "Epoch 6/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "Epoch 7/20\n",
      "928/928 [==============================] - 82s 88ms/step - loss: 0.0659 - val_loss: 0.0661\n",
      "Epoch 8/20\n",
      "928/928 [==============================] - 82s 88ms/step - loss: 0.0659 - val_loss: 0.0661\n",
      "Epoch 9/20\n",
      "928/928 [==============================] - 82s 88ms/step - loss: 0.0659 - val_loss: 0.0661\n",
      "Epoch 10/20\n",
      "928/928 [==============================] - 81s 88ms/step - loss: 0.0659 - val_loss: 0.0662\n",
      "Epoch 11/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0659 - val_loss: 0.0661\n",
      "Epoch 12/20\n",
      "928/928 [==============================] - 82s 89ms/step - loss: 0.0659 - val_loss: 0.0661\n",
      "Epoch 13/20\n",
      "928/928 [==============================] - 82s 89ms/step - loss: 0.0659 - val_loss: 0.0661\n",
      "Epoch 14/20\n",
      "928/928 [==============================] - 81s 88ms/step - loss: 0.0659 - val_loss: 0.0664\n",
      "Epoch 15/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0659 - val_loss: 0.0661\n",
      "Epoch 16/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0659 - val_loss: 0.0662\n",
      "Epoch 17/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0659 - val_loss: 0.0661\n",
      "Epoch 18/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0658 - val_loss: 0.0662\n",
      "Epoch 19/20\n",
      "928/928 [==============================] - 79s 86ms/step - loss: 0.0659 - val_loss: 0.0661\n",
      "Epoch 20/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0659 - val_loss: 0.0661\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC12rnn_rand_grad50_2k\\assets\n",
      "13 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_28 (LSTM)              (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_14 (RepeatVec  (None, 1, 100)           0         \n",
      " tor)                                                            \n",
      "                                                                 \n",
      " lstm_29 (LSTM)              (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_14 (TimeDi  (None, 1, 1)             101       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(148352, 12, 1) (148352,)\n",
      "Epoch 1/20\n",
      "  1/928 [..............................] - ETA: 1:28 - loss: 0.3272"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwangwoon\\anaconda3\\envs\\rnn-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0715 - val_loss: 0.0658\n",
      "Epoch 2/20\n",
      "928/928 [==============================] - 81s 88ms/step - loss: 0.0663 - val_loss: 0.0658\n",
      "Epoch 3/20\n",
      "928/928 [==============================] - 82s 88ms/step - loss: 0.0663 - val_loss: 0.0659\n",
      "Epoch 4/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0663 - val_loss: 0.0656\n",
      "Epoch 5/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0662 - val_loss: 0.0668\n",
      "Epoch 6/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0662 - val_loss: 0.0656\n",
      "Epoch 7/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0662 - val_loss: 0.0659\n",
      "Epoch 8/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0662 - val_loss: 0.0656\n",
      "Epoch 9/20\n",
      "928/928 [==============================] - 81s 88ms/step - loss: 0.0661 - val_loss: 0.0657\n",
      "Epoch 10/20\n",
      "928/928 [==============================] - 82s 88ms/step - loss: 0.0661 - val_loss: 0.0658\n",
      "Epoch 11/20\n",
      "928/928 [==============================] - 82s 88ms/step - loss: 0.0661 - val_loss: 0.0666\n",
      "Epoch 12/20\n",
      "928/928 [==============================] - 82s 88ms/step - loss: 0.0661 - val_loss: 0.0656\n",
      "Epoch 13/20\n",
      "928/928 [==============================] - 82s 88ms/step - loss: 0.0661 - val_loss: 0.0656\n",
      "Epoch 14/20\n",
      "928/928 [==============================] - 82s 88ms/step - loss: 0.0661 - val_loss: 0.0657\n",
      "Epoch 15/20\n",
      "928/928 [==============================] - 82s 88ms/step - loss: 0.0661 - val_loss: 0.0656\n",
      "Epoch 16/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0661 - val_loss: 0.0656\n",
      "Epoch 17/20\n",
      "928/928 [==============================] - 82s 88ms/step - loss: 0.0661 - val_loss: 0.0656\n",
      "Epoch 18/20\n",
      "928/928 [==============================] - 81s 88ms/step - loss: 0.0661 - val_loss: 0.0656\n",
      "Epoch 19/20\n",
      "928/928 [==============================] - 82s 88ms/step - loss: 0.0661 - val_loss: 0.0656\n",
      "Epoch 20/20\n",
      "928/928 [==============================] - 82s 88ms/step - loss: 0.0661 - val_loss: 0.0656\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC13rnn_rand_grad50_2k\\assets\n",
      "14 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_30 (LSTM)              (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_15 (RepeatVec  (None, 1, 100)           0         \n",
      " tor)                                                            \n",
      "                                                                 \n",
      " lstm_31 (LSTM)              (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_15 (TimeDi  (None, 1, 1)             101       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(148352, 12, 1) (148352,)\n",
      "Epoch 1/20\n",
      "  1/928 [..............................] - ETA: 1:41 - loss: 0.2890"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwangwoon\\anaconda3\\envs\\rnn-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "928/928 [==============================] - 82s 88ms/step - loss: 0.0710 - val_loss: 0.0658\n",
      "Epoch 2/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0663 - val_loss: 0.0660\n",
      "Epoch 3/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0662 - val_loss: 0.0663\n",
      "Epoch 4/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0662 - val_loss: 0.0666\n",
      "Epoch 5/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0661 - val_loss: 0.0657\n",
      "Epoch 6/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0661 - val_loss: 0.0659\n",
      "Epoch 7/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0661 - val_loss: 0.0657\n",
      "Epoch 8/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0661 - val_loss: 0.0658\n",
      "Epoch 9/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0661 - val_loss: 0.0662\n",
      "Epoch 10/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0660 - val_loss: 0.0658\n",
      "Epoch 11/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0660 - val_loss: 0.0658\n",
      "Epoch 12/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0660 - val_loss: 0.0658\n",
      "Epoch 13/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0660 - val_loss: 0.0663\n",
      "Epoch 14/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0660 - val_loss: 0.0658\n",
      "Epoch 15/20\n",
      "928/928 [==============================] - 80s 87ms/step - loss: 0.0660 - val_loss: 0.0660\n",
      "Epoch 16/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0658\n",
      "Epoch 17/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "Epoch 18/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0657\n",
      "Epoch 19/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0657\n",
      "Epoch 20/20\n",
      "928/928 [==============================] - 79s 86ms/step - loss: 0.0660 - val_loss: 0.0657\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC14rnn_rand_grad50_2k\\assets\n",
      "15 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_32 (LSTM)              (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_16 (RepeatVec  (None, 1, 100)           0         \n",
      " tor)                                                            \n",
      "                                                                 \n",
      " lstm_33 (LSTM)              (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_16 (TimeDi  (None, 1, 1)             101       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(148352, 12, 1) (148352,)\n",
      "Epoch 1/20\n",
      "  1/928 [..............................] - ETA: 1:31 - loss: 0.3231"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwangwoon\\anaconda3\\envs\\rnn-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0712 - val_loss: 0.0687\n",
      "Epoch 2/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0663 - val_loss: 0.0662\n",
      "Epoch 3/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0661 - val_loss: 0.0665\n",
      "Epoch 4/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0661 - val_loss: 0.0666\n",
      "Epoch 5/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0661 - val_loss: 0.0663\n",
      "Epoch 6/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0661 - val_loss: 0.0662\n",
      "Epoch 7/20\n",
      "928/928 [==============================] - 79s 86ms/step - loss: 0.0660 - val_loss: 0.0664\n",
      "Epoch 8/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0661 - val_loss: 0.0662\n",
      "Epoch 9/20\n",
      "928/928 [==============================] - 79s 85ms/step - loss: 0.0661 - val_loss: 0.0666\n",
      "Epoch 10/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0662\n",
      "Epoch 11/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0660 - val_loss: 0.0662\n",
      "Epoch 12/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0660 - val_loss: 0.0663\n",
      "Epoch 13/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0663\n",
      "Epoch 14/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0664\n",
      "Epoch 15/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0665\n",
      "Epoch 16/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0663\n",
      "Epoch 17/20\n",
      "928/928 [==============================] - 80s 86ms/step - loss: 0.0660 - val_loss: 0.0662\n",
      "Epoch 18/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0660 - val_loss: 0.0662\n",
      "Epoch 19/20\n",
      "928/928 [==============================] - 82s 88ms/step - loss: 0.0660 - val_loss: 0.0662\n",
      "Epoch 20/20\n",
      "928/928 [==============================] - 81s 87ms/step - loss: 0.0660 - val_loss: 0.0662\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC15rnn_rand_grad50_2k\\assets\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:3\"):\n",
    "    for mec_index in range(train_dataset.shape[2]): # mecs만큼 반복\n",
    "        print(mec_index,'mec 학습중 ...')\n",
    "        rnn_model = get_model()\n",
    "        print(rnn_model.summary())\n",
    "        print(X_train[mec_index].shape, Y_train[mec_index].shape)\n",
    "        rnn_model.fit(X_train[mec_index], Y_train[mec_index], epochs=20, validation_split=0.2, verbose=1, batch_size = 128)\n",
    "        rnn_model.save('./rnn_models/MEC'+str(mec_index)+'rnn_'+file_path[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOpUcXClG8ECcBkwzfPGTbR",
   "mount_file_id": "1ZHgDD_jTvpgXzoRBbhcNUoQwM3bh22wU",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rnn-gpu",
   "language": "python",
   "name": "rnn-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
