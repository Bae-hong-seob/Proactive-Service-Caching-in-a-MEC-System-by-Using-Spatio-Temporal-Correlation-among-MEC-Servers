{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1690642228271,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "C2y_S3-nJR4w",
    "outputId": "f5a19309-e562-4226-8b3b-fc8fbfe55488"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300, 9, 64)\n",
      "['train0.png', 'train1.png', 'train2.png', 'train3.png', 'train4.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import natsort\n",
    "from PIL import Image\n",
    "\n",
    "file_path = './heatmap_case1_0.2'\n",
    "file_list = os.listdir(file_path)\n",
    "file_list = natsort.natsorted(file_list, key=None, reverse=False, alg=0)\n",
    "\n",
    "num_of_files = len(file_list)\n",
    "\n",
    "# Assuming all images have the same height and width\n",
    "first_image = Image.open(os.path.join(file_path, file_list[0]))\n",
    "height, width = np.array(first_image).shape\n",
    "\n",
    "# Create an empty NumPy array to store the images\n",
    "image_array = np.empty((num_of_files, height, width))\n",
    "\n",
    "# Iterate through the file list and load images\n",
    "for i, file_name in enumerate(file_list):\n",
    "    image = Image.open(os.path.join(file_path, file_name))\n",
    "    image_array[i] = np.array(image)\n",
    "\n",
    "# image_array now contains the images as NumPy arrays\n",
    "print(image_array.shape)  # (num_of_files, height, width)\n",
    "print(file_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1690642228271,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "xEldMqsNUzZJ",
    "outputId": "d7b6866c-df6d-4a53-dbea-4969724a2324"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train0.png\n",
      "train1.png\n",
      "train2.png\n",
      "train3.png\n",
      "train4.png\n",
      "train5.png\n",
      "train6.png\n",
      "train7.png\n",
      "train8.png\n",
      "train9.png\n",
      "train10.png\n",
      "train11.png\n",
      "train12.png\n",
      "\n",
      "train1.png\n",
      "train2.png\n",
      "train3.png\n",
      "train4.png\n",
      "train5.png\n",
      "train6.png\n",
      "train7.png\n",
      "train8.png\n",
      "train9.png\n",
      "train10.png\n",
      "train11.png\n",
      "train12.png\n",
      "train13.png\n",
      "\n",
      "(1288, 13, 9, 64)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "num_of_frames = 13  # Specify the desired number of frames\n",
    "\n",
    "# Assuming all images have the same height and width\n",
    "first_image = Image.open(os.path.join(file_path, file_list[0]))\n",
    "height, width = np.array(first_image).shape[:2]\n",
    "\n",
    "# Create an empty NumPy array to store the images\n",
    "dataset = np.empty((num_of_files-num_of_frames+1, num_of_frames, height, width))\n",
    "\n",
    "# Iterate through the file list and load images\n",
    "for i in range(num_of_files-num_of_frames+1):\n",
    "    frame_images = file_list[i : i+num_of_frames]\n",
    "    for j, file_name in enumerate(frame_images):\n",
    "        if i < 2:\n",
    "            print(file_name)\n",
    "        image = Image.open(os.path.join(file_path, file_name))\n",
    "        dataset[i, j] = np.array(image)\n",
    "    if i < 2:\n",
    "        print()\n",
    "\n",
    "# dataset now contains the images bound into frames\n",
    "print(dataset.shape)  # (num_of_files // num_of_frames, num_of_frames, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1690642228271,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "8TrYB66sX_yI",
    "outputId": "2671a939-ca7d-496d-b750-d589adceb1d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1288, 13, 9, 64, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a channel dimension since the images are grayscale.\n",
    "dataset = np.expand_dims(dataset, axis=-1)\n",
    "dataset.shape #(num_of_samples, frames, height, width, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1690642228272,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "x8319gfKUkes",
    "outputId": "6c8e4095-c9f5-4cd6-bd53-9b1f0c44378c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1159, 13, 9, 64, 1) (129, 13, 9, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into train and validation sets using indexing to optimize memory.\n",
    "indexes = np.arange(dataset.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "train_index = indexes[: int(0.9 * dataset.shape[0])]\n",
    "val_index = indexes[int(0.9 * dataset.shape[0]) :]\n",
    "train_dataset = dataset[train_index]\n",
    "val_dataset = dataset[val_index]\n",
    "\n",
    "# Normalize the data to the 0-1 range.\n",
    "train_dataset = train_dataset / 255\n",
    "val_dataset = val_dataset / 255\n",
    "\n",
    "print(train_dataset.shape, val_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbydufV0bBt2"
   },
   "source": [
    "# RNN\n",
    "1. 각 MEC 당 128 input -> 128개 output.\n",
    "2. 과거 12개 관찰."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 8097,
     "status": "ok",
     "timestamp": 1690642236366,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "RHWKfIYubBt3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "window_size  = 12\n",
    "\n",
    "def create_shifted_frames(data, mec_index): # data = (frames, mecs, movieId, gray_scale)\n",
    "    tmp_data = data[:,mec_index,:,:]\n",
    "    tmp_data = np.squeeze(tmp_data)\n",
    "    tmp_data = tmp_data.transpose()\n",
    "\n",
    "    return tmp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1777,
     "status": "ok",
     "timestamp": 1690642238140,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "CCoGOWQ-bBt3",
    "outputId": "0c22e886-8587-4cab-d196-bc559497625e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 1, 100)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 1, 1)             101       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    inputs = layers.Input(shape=(window_size,1))\n",
    "    encoder = layers.LSTM(100, activation=\"relu\", return_sequences=False)(inputs)\n",
    "    repeat = layers.RepeatVector(1)(encoder)\n",
    "    decoder = layers.LSTM(100, activation='relu', return_sequences=True)(repeat)\n",
    "    outputs = layers.TimeDistributed(layers.Dense(1))(decoder)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    return model\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# observe_mec_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4876430,
     "status": "ok",
     "timestamp": 1690647114566,
     "user": {
      "displayName": "배홍섭",
      "userId": "04508707267981176802"
     },
     "user_tz": -540
    },
    "id": "IymkXeEtVJrj",
    "outputId": "97fa4628-d8eb-46b8-d98c-0359eb03648f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1158  train ...\n",
      "no observe mec index\n",
      "8  번째 mec 학습 데이터 생성중 ...\n",
      "(64, 13)\n",
      "frame shape :  (64, 13)\n",
      "0  movie  train ...  (13,)\n",
      "1  movie  train ...  (13,)\n",
      "2  movie  train ...  (13,)\n",
      "3  movie  train ...  (13,)\n",
      "4  movie  train ...  (13,)\n",
      "5  movie  train ...  (13,)\n",
      "6  movie  train ...  (13,)\n",
      "7  movie  train ...  (13,)\n",
      "8  movie  train ...  (13,)\n",
      "9  movie  train ...  (13,)\n",
      "10  movie  train ...  (13,)\n",
      "11  movie  train ...  (13,)\n",
      "12  movie  train ...  (13,)\n",
      "13  movie  train ...  (13,)\n",
      "14  movie  train ...  (13,)\n",
      "15  movie  train ...  (13,)\n",
      "16  movie  train ...  (13,)\n",
      "17  movie  train ...  (13,)\n",
      "18  movie  train ...  (13,)\n",
      "19  movie  train ...  (13,)\n",
      "20  movie  train ...  (13,)\n",
      "21  movie  train ...  (13,)\n",
      "22  movie  train ...  (13,)\n",
      "23  movie  train ...  (13,)\n",
      "24  movie  train ...  (13,)\n",
      "25  movie  train ...  (13,)\n",
      "26  movie  train ...  (13,)\n",
      "27  movie  train ...  (13,)\n",
      "28  movie  train ...  (13,)\n",
      "29  movie  train ...  (13,)\n",
      "30  movie  train ...  (13,)\n",
      "31  movie  train ...  (13,)\n",
      "32  movie  train ...  (13,)\n",
      "33  movie  train ...  (13,)\n",
      "34  movie  train ...  (13,)\n",
      "35  movie  train ...  (13,)\n",
      "36  movie  train ...  (13,)\n",
      "37  movie  train ...  (13,)\n",
      "38  movie  train ...  (13,)\n",
      "39  movie  train ...  (13,)\n",
      "40  movie  train ...  (13,)\n",
      "41  movie  train ...  (13,)\n",
      "42  movie  train ...  (13,)\n",
      "43  movie  train ...  (13,)\n",
      "44  movie  train ...  (13,)\n",
      "45  movie  train ...  (13,)\n",
      "46  movie  train ...  (13,)\n",
      "47  movie  train ...  (13,)\n",
      "48  movie  train ...  (13,)\n",
      "49  movie  train ...  (13,)\n",
      "50  movie  train ...  (13,)\n",
      "51  movie  train ...  (13,)\n",
      "52  movie  train ...  (13,)\n",
      "53  movie  train ...  (13,)\n",
      "54  movie  train ...  (13,)\n",
      "55  movie  train ...  (13,)\n",
      "56  movie  train ...  (13,)\n",
      "57  movie  train ...  (13,)\n",
      "58  movie  train ...  (13,)\n",
      "59  movie  train ...  (13,)\n",
      "60  movie  train ...  (13,)\n",
      "61  movie  train ...  (13,)\n",
      "62  movie  train ...  (13,)\n",
      "63  movie  train ...  (13,)\n",
      "(9, 74176, 12, 1) (9, 74176)\n"
     ]
    }
   ],
   "source": [
    "X_train = [[] for _ in range(train_dataset.shape[2])]\n",
    "Y_train = [[] for _ in range(train_dataset.shape[2])]\n",
    "\n",
    "for day_index, oneday_dataset in enumerate(train_dataset):\n",
    "    for mec_index in range(oneday_dataset.shape[1]):\n",
    "        clear_output(wait=True)\n",
    "        print(day_index, ' train ...')\n",
    "        \n",
    "        try:\n",
    "            if mec_index != observe_mec_index:\n",
    "                continue\n",
    "        except:\n",
    "            print('no observe mec index')\n",
    "\n",
    "        print(mec_index,' 번째 mec 학습 데이터 생성중 ...')\n",
    "        frame_dataset = create_shifted_frames(oneday_dataset, mec_index)\n",
    "        print('frame shape : ', frame_dataset.shape)\n",
    "\n",
    "        X,Y = np.empty((1,12,1)), np.empty((1))\n",
    "        for movieId_index, movieId in enumerate(frame_dataset):\n",
    "            print(movieId_index, ' movie  train ... ', movieId.shape)\n",
    "            x = movieId[:-1]\n",
    "            x = np.array([[x[i] for i in range(j,j+window_size)] for j in range(len(x)-window_size+1)])\n",
    "            y = movieId[window_size:]\n",
    "            x = np.expand_dims(x, axis=-1)\n",
    "            #print('final X,Y shape : ',  x.shape, y.shape)\n",
    "            X = np.append(X,x, axis=0)\n",
    "            Y = np.append(Y,y, axis=0)\n",
    "\n",
    "        X = np.delete(X, 0, axis=0)\n",
    "        Y = np.delete(Y, 0, axis=0)\n",
    "        try:\n",
    "            X_train[mec_index].extend(X)\n",
    "            Y_train[mec_index].extend(Y)\n",
    "        except:\n",
    "            X_train[mec_index] = np.append(X_train[mec_index], X, axis=0)\n",
    "            Y_train[mec_index] = np.append(Y_train[mec_index], Y, axis=0)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_1 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(74176, 12, 1) (74176,)\n",
      "Epoch 1/20\n",
      "464/464 [==============================] - 69s 140ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "Epoch 2/20\n",
      "464/464 [==============================] - 66s 140ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "Epoch 3/20\n",
      "464/464 [==============================] - 68s 146ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "Epoch 4/20\n",
      "464/464 [==============================] - 64s 139ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "Epoch 5/20\n",
      "464/464 [==============================] - 64s 138ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "Epoch 6/20\n",
      "464/464 [==============================] - 63s 136ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "Epoch 7/20\n",
      "464/464 [==============================] - 63s 137ms/step - loss: 0.0245 - val_loss: 0.0251\n",
      "Epoch 8/20\n",
      "464/464 [==============================] - 64s 138ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "Epoch 9/20\n",
      "464/464 [==============================] - 63s 135ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "Epoch 10/20\n",
      "464/464 [==============================] - 62s 134ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "Epoch 11/20\n",
      "464/464 [==============================] - 63s 135ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "Epoch 12/20\n",
      "464/464 [==============================] - 65s 140ms/step - loss: 0.0245 - val_loss: 0.0251\n",
      "Epoch 13/20\n",
      "464/464 [==============================] - 63s 135ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "Epoch 14/20\n",
      "464/464 [==============================] - 64s 138ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "Epoch 15/20\n",
      "464/464 [==============================] - 65s 141ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "Epoch 16/20\n",
      "464/464 [==============================] - 64s 138ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "Epoch 17/20\n",
      "464/464 [==============================] - 64s 138ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "Epoch 18/20\n",
      "464/464 [==============================] - 65s 139ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "Epoch 19/20\n",
      "464/464 [==============================] - 64s 137ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "Epoch 20/20\n",
      "464/464 [==============================] - 64s 139ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC0rnn_case1_0.2\\assets\n",
      "1 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_2 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(74176, 12, 1) (74176,)\n",
      "Epoch 1/20\n",
      "464/464 [==============================] - 66s 138ms/step - loss: 0.0237 - val_loss: 0.0234\n",
      "Epoch 2/20\n",
      "464/464 [==============================] - 64s 138ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 3/20\n",
      "464/464 [==============================] - 64s 138ms/step - loss: 0.0237 - val_loss: 0.0234\n",
      "Epoch 4/20\n",
      "464/464 [==============================] - 62s 134ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 5/20\n",
      "464/464 [==============================] - 64s 138ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 6/20\n",
      "464/464 [==============================] - 65s 141ms/step - loss: 0.0237 - val_loss: 0.0234\n",
      "Epoch 7/20\n",
      "464/464 [==============================] - 64s 138ms/step - loss: 0.0237 - val_loss: 0.0234\n",
      "Epoch 8/20\n",
      "464/464 [==============================] - 63s 135ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 9/20\n",
      "464/464 [==============================] - 64s 138ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 10/20\n",
      "464/464 [==============================] - 63s 137ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 11/20\n",
      "464/464 [==============================] - 62s 134ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 12/20\n",
      "464/464 [==============================] - 62s 134ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 13/20\n",
      "464/464 [==============================] - 62s 133ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 14/20\n",
      "464/464 [==============================] - 62s 135ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 15/20\n",
      "464/464 [==============================] - 62s 134ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 16/20\n",
      "464/464 [==============================] - 62s 134ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 17/20\n",
      "464/464 [==============================] - 65s 141ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 18/20\n",
      "464/464 [==============================] - 64s 138ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 19/20\n",
      "464/464 [==============================] - 63s 135ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 20/20\n",
      "464/464 [==============================] - 66s 141ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC1rnn_case1_0.2\\assets\n",
      "2 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_3 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(74176, 12, 1) (74176,)\n",
      "Epoch 1/20\n",
      "464/464 [==============================] - 66s 138ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 2/20\n",
      "464/464 [==============================] - 61s 131ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 3/20\n",
      "464/464 [==============================] - 64s 138ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 4/20\n",
      "464/464 [==============================] - 62s 134ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 5/20\n",
      "464/464 [==============================] - 63s 137ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 6/20\n",
      "464/464 [==============================] - 62s 134ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 7/20\n",
      "464/464 [==============================] - 63s 135ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 8/20\n",
      "464/464 [==============================] - 64s 138ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 9/20\n",
      "464/464 [==============================] - 63s 137ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 10/20\n",
      "464/464 [==============================] - 66s 142ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 11/20\n",
      "464/464 [==============================] - 65s 140ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 12/20\n",
      "464/464 [==============================] - 66s 142ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 13/20\n",
      "464/464 [==============================] - 42s 90ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 14/20\n",
      "464/464 [==============================] - 29s 63ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 15/20\n",
      "464/464 [==============================] - 30s 64ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 16/20\n",
      "464/464 [==============================] - 30s 65ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 17/20\n",
      "464/464 [==============================] - 30s 64ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 18/20\n",
      "464/464 [==============================] - 30s 64ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 19/20\n",
      "464/464 [==============================] - 30s 65ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 20/20\n",
      "464/464 [==============================] - 30s 64ms/step - loss: 0.0260 - val_loss: 0.0256\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC2rnn_case1_0.2\\assets\n",
      "3 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_4 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(74176, 12, 1) (74176,)\n",
      "Epoch 1/20\n",
      "464/464 [==============================] - 32s 65ms/step - loss: 0.0241 - val_loss: 0.0246\n",
      "Epoch 2/20\n",
      "464/464 [==============================] - 30s 65ms/step - loss: 0.0240 - val_loss: 0.0246\n",
      "Epoch 3/20\n",
      "464/464 [==============================] - 30s 64ms/step - loss: 0.0240 - val_loss: 0.0246\n",
      "Epoch 4/20\n",
      "464/464 [==============================] - 30s 64ms/step - loss: 0.0240 - val_loss: 0.0246\n",
      "Epoch 5/20\n",
      "464/464 [==============================] - 30s 65ms/step - loss: 0.0240 - val_loss: 0.0246\n",
      "Epoch 6/20\n",
      "464/464 [==============================] - 30s 64ms/step - loss: 0.0240 - val_loss: 0.0246\n",
      "Epoch 7/20\n",
      "464/464 [==============================] - 30s 64ms/step - loss: 0.0240 - val_loss: 0.0246\n",
      "Epoch 8/20\n",
      "464/464 [==============================] - 30s 65ms/step - loss: 0.0240 - val_loss: 0.0246\n",
      "Epoch 9/20\n",
      "464/464 [==============================] - 30s 64ms/step - loss: 0.0240 - val_loss: 0.0246\n",
      "Epoch 10/20\n",
      "464/464 [==============================] - 24s 52ms/step - loss: 0.0240 - val_loss: 0.0247\n",
      "Epoch 11/20\n",
      "464/464 [==============================] - 24s 53ms/step - loss: 0.0240 - val_loss: 0.0246\n",
      "Epoch 12/20\n",
      "464/464 [==============================] - 25s 53ms/step - loss: 0.0240 - val_loss: 0.0246\n",
      "Epoch 13/20\n",
      "464/464 [==============================] - 24s 53ms/step - loss: 0.0240 - val_loss: 0.0246\n",
      "Epoch 14/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0240 - val_loss: 0.0246\n",
      "Epoch 15/20\n",
      "464/464 [==============================] - 27s 59ms/step - loss: 0.0240 - val_loss: 0.0246\n",
      "Epoch 16/20\n",
      "464/464 [==============================] - 27s 59ms/step - loss: 0.0240 - val_loss: 0.0246\n",
      "Epoch 17/20\n",
      "464/464 [==============================] - 27s 59ms/step - loss: 0.0240 - val_loss: 0.0246\n",
      "Epoch 18/20\n",
      "464/464 [==============================] - 27s 58ms/step - loss: 0.0240 - val_loss: 0.0246\n",
      "Epoch 19/20\n",
      "464/464 [==============================] - 25s 54ms/step - loss: 0.0240 - val_loss: 0.0246\n",
      "Epoch 20/20\n",
      "464/464 [==============================] - 25s 54ms/step - loss: 0.0240 - val_loss: 0.0246\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC3rnn_case1_0.2\\assets\n",
      "4 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_5 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(74176, 12, 1) (74176,)\n",
      "Epoch 1/20\n",
      "464/464 [==============================] - 28s 57ms/step - loss: 0.0229 - val_loss: 0.0227\n",
      "Epoch 2/20\n",
      "464/464 [==============================] - 27s 58ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 3/20\n",
      "464/464 [==============================] - 27s 58ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 4/20\n",
      "464/464 [==============================] - 27s 58ms/step - loss: 0.0228 - val_loss: 0.0227\n",
      "Epoch 5/20\n",
      "464/464 [==============================] - 27s 58ms/step - loss: 0.0228 - val_loss: 0.0227\n",
      "Epoch 6/20\n",
      "464/464 [==============================] - 27s 59ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 7/20\n",
      "464/464 [==============================] - 27s 58ms/step - loss: 0.0228 - val_loss: 0.0227\n",
      "Epoch 8/20\n",
      "464/464 [==============================] - 27s 58ms/step - loss: 0.0228 - val_loss: 0.0227\n",
      "Epoch 9/20\n",
      "464/464 [==============================] - 27s 58ms/step - loss: 0.0228 - val_loss: 0.0227\n",
      "Epoch 10/20\n",
      "464/464 [==============================] - 27s 58ms/step - loss: 0.0228 - val_loss: 0.0227\n",
      "Epoch 11/20\n",
      "464/464 [==============================] - 27s 58ms/step - loss: 0.0228 - val_loss: 0.0227\n",
      "Epoch 12/20\n",
      "464/464 [==============================] - 27s 58ms/step - loss: 0.0228 - val_loss: 0.0227\n",
      "Epoch 13/20\n",
      "464/464 [==============================] - 27s 57ms/step - loss: 0.0228 - val_loss: 0.0227\n",
      "Epoch 14/20\n",
      "464/464 [==============================] - 27s 58ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 15/20\n",
      "464/464 [==============================] - 27s 59ms/step - loss: 0.0228 - val_loss: 0.0227\n",
      "Epoch 16/20\n",
      "464/464 [==============================] - 27s 58ms/step - loss: 0.0228 - val_loss: 0.0227\n",
      "Epoch 17/20\n",
      "464/464 [==============================] - 27s 59ms/step - loss: 0.0228 - val_loss: 0.0227\n",
      "Epoch 18/20\n",
      "464/464 [==============================] - 27s 58ms/step - loss: 0.0228 - val_loss: 0.0227\n",
      "Epoch 19/20\n",
      "464/464 [==============================] - 27s 58ms/step - loss: 0.0228 - val_loss: 0.0227\n",
      "Epoch 20/20\n",
      "464/464 [==============================] - 27s 58ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC4rnn_case1_0.2\\assets\n",
      "5 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_6 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(74176, 12, 1) (74176,)\n",
      "Epoch 1/20\n",
      "464/464 [==============================] - 29s 59ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 2/20\n",
      "464/464 [==============================] - 27s 59ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 3/20\n",
      "464/464 [==============================] - 28s 59ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 4/20\n",
      "464/464 [==============================] - 27s 59ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 5/20\n",
      "464/464 [==============================] - 27s 59ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 6/20\n",
      "464/464 [==============================] - 27s 59ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 7/20\n",
      "464/464 [==============================] - 27s 59ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 8/20\n",
      "464/464 [==============================] - 27s 59ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 9/20\n",
      "464/464 [==============================] - 27s 58ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 10/20\n",
      "464/464 [==============================] - 28s 59ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 11/20\n",
      "464/464 [==============================] - 27s 59ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 12/20\n",
      "464/464 [==============================] - 27s 59ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 13/20\n",
      "464/464 [==============================] - 27s 59ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 14/20\n",
      "464/464 [==============================] - 27s 59ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 15/20\n",
      "464/464 [==============================] - 27s 59ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 16/20\n",
      "464/464 [==============================] - 27s 58ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 17/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 18/20\n",
      "464/464 [==============================] - 27s 58ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 19/20\n",
      "464/464 [==============================] - 27s 57ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 20/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC5rnn_case1_0.2\\assets\n",
      "6 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_7 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(74176, 12, 1) (74176,)\n",
      "Epoch 1/20\n",
      "464/464 [==============================] - 28s 56ms/step - loss: 0.0253 - val_loss: 0.0250\n",
      "Epoch 2/20\n",
      "464/464 [==============================] - 26s 56ms/step - loss: 0.0253 - val_loss: 0.0250\n",
      "Epoch 3/20\n",
      "464/464 [==============================] - 26s 56ms/step - loss: 0.0253 - val_loss: 0.0251\n",
      "Epoch 4/20\n",
      "464/464 [==============================] - 27s 58ms/step - loss: 0.0253 - val_loss: 0.0250\n",
      "Epoch 5/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0253 - val_loss: 0.0251\n",
      "Epoch 6/20\n",
      "464/464 [==============================] - 27s 57ms/step - loss: 0.0253 - val_loss: 0.0251\n",
      "Epoch 7/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0253 - val_loss: 0.0250\n",
      "Epoch 8/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0253 - val_loss: 0.0251\n",
      "Epoch 9/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0253 - val_loss: 0.0250\n",
      "Epoch 10/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0253 - val_loss: 0.0250\n",
      "Epoch 11/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0253 - val_loss: 0.0250\n",
      "Epoch 12/20\n",
      "464/464 [==============================] - 27s 58ms/step - loss: 0.0253 - val_loss: 0.0251\n",
      "Epoch 13/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0253 - val_loss: 0.0251\n",
      "Epoch 14/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0253 - val_loss: 0.0250\n",
      "Epoch 15/20\n",
      "464/464 [==============================] - 27s 57ms/step - loss: 0.0253 - val_loss: 0.0250\n",
      "Epoch 16/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0253 - val_loss: 0.0251\n",
      "Epoch 17/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0253 - val_loss: 0.0250\n",
      "Epoch 18/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0253 - val_loss: 0.0250\n",
      "Epoch 19/20\n",
      "464/464 [==============================] - 26s 56ms/step - loss: 0.0253 - val_loss: 0.0250\n",
      "Epoch 20/20\n",
      "464/464 [==============================] - 26s 56ms/step - loss: 0.0253 - val_loss: 0.0250\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC6rnn_case1_0.2\\assets\n",
      "7 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_8 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_8 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(74176, 12, 1) (74176,)\n",
      "Epoch 1/20\n",
      "464/464 [==============================] - 29s 57ms/step - loss: 0.0237 - val_loss: 0.0236\n",
      "Epoch 2/20\n",
      "464/464 [==============================] - 26s 56ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 3/20\n",
      "464/464 [==============================] - 26s 56ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 4/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 5/20\n",
      "464/464 [==============================] - 26s 56ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 6/20\n",
      "464/464 [==============================] - 26s 56ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 7/20\n",
      "464/464 [==============================] - 27s 57ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 8/20\n",
      "464/464 [==============================] - 27s 58ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 9/20\n",
      "464/464 [==============================] - 27s 57ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 10/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 11/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 12/20\n",
      "464/464 [==============================] - 27s 58ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 13/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 14/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 15/20\n",
      "464/464 [==============================] - 26s 56ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 16/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 17/20\n",
      "464/464 [==============================] - 26s 56ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 18/20\n",
      "464/464 [==============================] - 26s 56ms/step - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 19/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0236 - val_loss: 0.0236\n",
      "Epoch 20/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0236 - val_loss: 0.0236\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC7rnn_case1_0.2\\assets\n",
      "8 mec 학습중 ...\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 12, 1)]           0         \n",
      "                                                                 \n",
      " lstm_18 (LSTM)              (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_9 (RepeatVect  (None, 1, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed_9 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(74176, 12, 1) (74176,)\n",
      "Epoch 1/20\n",
      "464/464 [==============================] - 28s 57ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 2/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 3/20\n",
      "464/464 [==============================] - 26s 56ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 4/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 5/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 6/20\n",
      "464/464 [==============================] - 27s 57ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 7/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 8/20\n",
      "464/464 [==============================] - 27s 57ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 9/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 10/20\n",
      "464/464 [==============================] - 26s 56ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 11/20\n",
      "464/464 [==============================] - 26s 56ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 12/20\n",
      "464/464 [==============================] - 26s 56ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 13/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 14/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 15/20\n",
      "464/464 [==============================] - 26s 56ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 16/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 17/20\n",
      "464/464 [==============================] - 26s 56ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 18/20\n",
      "464/464 [==============================] - 26s 56ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 19/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 20/20\n",
      "464/464 [==============================] - 26s 57ms/step - loss: 0.0256 - val_loss: 0.0245\n",
      "INFO:tensorflow:Assets written to: ./rnn_models/MEC8rnn_case1_0.2\\assets\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    for mec_index in range(train_dataset.shape[2]): # mecs만큼 반복\n",
    "        print(mec_index,'mec 학습중 ...')\n",
    "        rnn_model = get_model()\n",
    "        print(rnn_model.summary())\n",
    "        print(X_train[mec_index].shape, Y_train[mec_index].shape)\n",
    "        rnn_model.fit(X_train[mec_index], Y_train[mec_index], epochs=20, validation_split=0.2, verbose=1, batch_size = 128)\n",
    "        rnn_model.save('./rnn_models/MEC'+str(mec_index)+'rnn_'+file_path[-9:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = [[] for _ in range(val_dataset.shape[2])]\n",
    "Y_val = [[] for _ in range(val_dataset.shape[2])]\n",
    "\n",
    "for day_index, oneday_dataset in enumerate(val_dataset):\n",
    "    for mec_index in range(oneday_dataset.shape[1]):\n",
    "        clear_output(wait=True)\n",
    "        print(day_index, ' val ...')\n",
    "        \n",
    "        try:\n",
    "            if mec_index != observe_mec_index:\n",
    "                continue\n",
    "        except:\n",
    "            print('no observe mec index')\n",
    "\n",
    "        print(mec_index,' 번째 mec 검증 데이터 생성중 ...')\n",
    "        frame_dataset = create_shifted_frames(oneday_dataset, mec_index)\n",
    "        print('frame shape : ', frame_dataset.shape)\n",
    "\n",
    "        X,Y = np.empty((1,12,1)), np.empty((1))\n",
    "        for movieId_index, movieId in enumerate(frame_dataset):\n",
    "            print(movieId_index, ' movie  val ... ', movieId.shape)\n",
    "            x = movieId[:-1]\n",
    "            x = np.array([[x[i] for i in range(j,j+window_size)] for j in range(len(x)-window_size+1)])\n",
    "            y = movieId[window_size:]\n",
    "            x = np.expand_dims(x, axis=-1)\n",
    "            #print('final X,Y shape : ',  x.shape, y.shape)\n",
    "            X = np.append(X,x, axis=0)\n",
    "            Y = np.append(Y,y, axis=0)\n",
    "\n",
    "        X = np.delete(X, 0, axis=0)\n",
    "        Y = np.delete(Y, 0, axis=0)\n",
    "        try:\n",
    "            X_val[mec_index].extend(X)\n",
    "            Y_val[mec_index].extend(Y)\n",
    "        except:\n",
    "            X_val[mec_index] = np.append(X_val[mec_index], X, axis=0)\n",
    "            Y_val[mec_index] = np.append(Y_val[mec_index], Y, axis=0)\n",
    "\n",
    "X_val = np.array(X_val)\n",
    "Y_val = np.array(Y_val)\n",
    "print(X_val.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    predictions = [[] for _ in range(val_dataset.shape[2])]\n",
    "    for mec_index in range(val_dataset.shape[2]): # mecs만큼 반복\n",
    "        print(mec_index,'mec 예측중 ...')\n",
    "        model = keras.models.load_model('./rnn_models/MEC'+str(mec_index)+'rnn_'+file_path[-9:])\n",
    "        predictions[mec_index].extend(model.predict(X_val[mec_index], verbose=0))\n",
    "    predictions = np.array(predictions)\n",
    "    print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.squeeze()\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 8\n",
    "\n",
    "def find_top_k_indices(matrix):\n",
    "    result = []\n",
    "    if len(matrix.shape) == 2: # matrix인 경우\n",
    "        for row in matrix:\n",
    "            mecs_top_k = []\n",
    "            # (인덱스, 값) 쌍으로 이루어진 리스트를 생성합니다.\n",
    "            indices_values = [(index, value) for index, value in enumerate(row)]\n",
    "            #print(indices_values)\n",
    "            # 값에 따라 정렬합니다. (큰 값이 먼저 오도록)\n",
    "            sorted_indices_values = sorted(indices_values, key=lambda x: x[1], reverse=True)\n",
    "            # 상위 32개의 인덱스를 결과에 추가합니다.\n",
    "            top_indices = [index for index, _ in sorted_indices_values[:K]]\n",
    "            mecs_top_k.extend(top_indices)\n",
    "            result.append(mecs_top_k)\n",
    "        return result\n",
    "    \n",
    "    elif len(matrix.shape) == 1: # list 인 경우 \n",
    "        indices_values = [(index, value) for index, value in enumerate(matrix)]\n",
    "        sorted_indices_values = sorted(indices_values, key=lambda x:x[1], reverse=True)\n",
    "        top_indices = [index for index,_ in sorted_indices_values[:K]]\n",
    "        result.extend(top_indices)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random example from the validation dataset.\n",
    "np.random.seed(42)\n",
    "total_hits_list = [[] for _ in range(val_dataset.shape[2])] # mecs수 만큼 빈 객체 생성\n",
    "\n",
    "for i in range(0, Y_val.shape[1], val_dataset.shape[3]):\n",
    "    truths = Y_val[:,i:i+val_dataset.shape[3]] # 64개씩 짤라서 matrix(=image) 생성\n",
    "    prediction = predictions[:, i:i+val_dataset.shape[3]]\n",
    "    #print(truths.shape, prediction.shape)\n",
    "\n",
    "    top_k_truths = find_top_k_indices(truths)\n",
    "    top_k_predicts = find_top_k_indices(prediction)\n",
    "\n",
    "    total_hits = 0\n",
    "    for idx, (truths_mecs, predict_mecs) in enumerate(zip(top_k_truths, top_k_predicts)):\n",
    "        hits_per_mecs = sum([1 for i in truths_mecs if i in predict_mecs])\n",
    "        total_hits_list[idx].append(hits_per_mecs)\n",
    "        total_hits += hits_per_mecs\n",
    "    \n",
    "print('hit rate log 개수 : ', len(total_hits_list))\n",
    "print('hit rate log per mec : ', len(total_hits_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "total_hits_rate = 0\n",
    "total_hits_per_mecs = []\n",
    "\n",
    "for hits_per_mecs in total_hits_list:\n",
    "    total_hits_per_mecs.append(sum(hits_per_mecs))\n",
    "\n",
    "total_hits_rate_per_mecs = [total_hits_per_mec / val_dataset.shape[0] for total_hits_per_mec in total_hits_per_mecs]# mecs 수로 나누어줌\n",
    "total_hits_rate = sum(total_hits_per_mecs) / (val_dataset.shape[0] * val_dataset.shape[2])\n",
    "\n",
    "print('mecs 별 평균 : ', total_hits_rate_per_mecs)\n",
    "print('전체 mecs 평균 : ', total_hits_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_rate_per_mecs = (np.array(total_hits_rate_per_mecs) / K) * 100\n",
    "\n",
    "print('hit rate per mec : ', hits_rate_per_mecs)\n",
    "print('hit rate total mec (mean/variance/std) : ', hits_rate_per_mecs.mean(), hits_rate_per_mecs.var(),hits_rate_per_mecs.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boxplot 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_hits_rate_list = (np.array(total_hits_list) / K) * 100\n",
    "total_hits_rate_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_hits_rate_list = list(total_hits_rate_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming total_hits_list is a 2D list with 16 rows and 143 columns\n",
    "# Each row represents the hit rate data for one MEC.\n",
    "\n",
    "# Create a list of labels for the 16 MECs (e.g., MEC_1, MEC_2, ..., MEC_16)\n",
    "mec_labels = [f\"{i}\" for i in range(image_array.shape[1])]\n",
    "\n",
    "# Create a figure and axis object for the boxplot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create the boxplot using the boxplot function\n",
    "ax.boxplot(total_hits_rate_list, labels=mec_labels)\n",
    "\n",
    "# Set axis labels and title\n",
    "ax.set_xlabel('MECs index')\n",
    "ax.set_ylabel('Conformity degree(%)')\n",
    "#ax.set_title('Hit Rate Distribution for '+str(val_dataset.shape[2])+ ' MECs')\n",
    "\n",
    "# Save the plot.png\n",
    "plt.savefig('./Figs/'+file_path[-9:]+'_K='+str(K)+'.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test set 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4CJUWYEjCfye"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOpUcXClG8ECcBkwzfPGTbR",
   "mount_file_id": "1ZHgDD_jTvpgXzoRBbhcNUoQwM3bh22wU",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rnn-gpu",
   "language": "python",
   "name": "rnn-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
